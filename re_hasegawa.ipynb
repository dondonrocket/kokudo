{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/8jhpzNDwDVM/2VIV+C3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondonrocket/kokudo/blob/%EF%BC%91%EF%BC%97%EF%BC%8E%EF%BC%90%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89base/re_hasegawa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "a7Wc9jfop15s"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# 1) 読み込み & 定義（完成度重視）\n",
        "#  - 列名ゆらぎに強い\n",
        "#  - 2/3/4で使う定数・関数をここで完備\n",
        "# =========================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================================================\n",
        "# 乱数・基本設定\n",
        "# =========================================================\n",
        "SEED = 2025\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# =========================================================\n",
        "# パス定義\n",
        "# =========================================================\n",
        "DATA_DIR = Path(\"/content\")  # Colab想定\n",
        "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
        "TEST_PATH  = DATA_DIR / \"test.csv\"\n",
        "\n",
        "# -------------------------\n",
        "# 重要列（確定しているもの）\n",
        "# -------------------------\n",
        "ID_COL     = \"building_id\"\n",
        "TARGET_COL = \"money_room\"\n",
        "YM_COL     = \"target_ym\"\n",
        "BUILDING_TYPE_COL = \"building_type\"\n",
        "\n",
        "# -------------------------\n",
        "# 時系列設定（README準拠）\n",
        "# -------------------------\n",
        "BASE_YEAR = 2019  # elapsed_months の基準\n",
        "\n",
        "# -------------------------\n",
        "# distance列のNaN対策（Step2で使う設定）\n",
        "# -------------------------\n",
        "DIST_SUFFIX = \"_distance\"\n",
        "# 大きな定数埋めの方針：trainの分位点で決める（例：0.99）\n",
        "DIST_FILL_QUANTILE = 0.99\n",
        "\n",
        "# =========================================================\n",
        "# 便利関数：読み込み\n",
        "# =========================================================\n",
        "def read_csv_sjis(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Shift-JIS前提の安定読み込み（このコンペに合わせる）\"\"\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    return pd.read_csv(\n",
        "        path,\n",
        "        encoding=\"shift_jis\",\n",
        "        encoding_errors=\"replace\",\n",
        "        low_memory=False\n",
        "    )\n",
        "\n",
        "def ensure_required_columns(df: pd.DataFrame, required: list[str], name: str):\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        # ここで止めるのが完成度（後段で謎バグにしない）\n",
        "        raise KeyError(f\"[{name}] missing columns: {missing}\")\n",
        "\n",
        "# =========================================================\n",
        "# 便利関数：列名ゆらぎ対応（lon/latなどが揺れる前提）\n",
        "# =========================================================\n",
        "def pick_first_existing(df: pd.DataFrame, candidates: list[str]) -> str:\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise KeyError(f\"None of candidates exist: {candidates}\")\n",
        "\n",
        "# lon/lat はコンペで揺れがちなので候補を多めに持つ\n",
        "LON_CANDIDATES = [\"lon\", \"longitude\", \"x\", \"X\", \"経度\"]\n",
        "LAT_CANDIDATES = [\"lat\", \"latitude\", \"y\", \"Y\", \"緯度\"]\n",
        "\n",
        "# =========================================================\n",
        "# 便利関数：時間列追加（Step2以降で使う前提列）\n",
        "# =========================================================\n",
        "def add_time_columns(df: pd.DataFrame, ym_col: str = YM_COL, base_year: int = BASE_YEAR) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    ym = pd.to_numeric(df[ym_col], errors=\"coerce\")\n",
        "    year = (ym // 100).astype(\"Int64\")\n",
        "    month = (ym % 100).astype(\"Int64\")\n",
        "\n",
        "    df[\"year\"] = year\n",
        "    df[\"month\"] = month\n",
        "    df[\"elapsed_months\"] = (df[\"year\"] - base_year) * 12 + (df[\"month\"] - 1)\n",
        "    return df\n",
        "\n",
        "# =========================================================\n",
        "# 便利関数：distance列検出（Step2でNaN処理対象にする）\n",
        "# =========================================================\n",
        "def get_distance_cols(df: pd.DataFrame, suffix: str = DIST_SUFFIX) -> list[str]:\n",
        "    return [c for c in df.columns if c.endswith(suffix)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 読み込み\n",
        "# =========================================================\n",
        "train = read_csv_sjis(TRAIN_PATH)\n",
        "test  = read_csv_sjis(TEST_PATH)"
      ],
      "metadata": {
        "id": "322pg9pCqBZs"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 必須列チェック（ここで落とすのが正解）\n",
        "# =========================================================\n",
        "ensure_required_columns(train, [ID_COL, TARGET_COL, YM_COL, BUILDING_TYPE_COL], \"train\")\n",
        "ensure_required_columns(test,  [ID_COL, YM_COL, BUILDING_TYPE_COL], \"test\")\n",
        "\n",
        "# lon/lat は列名が揺れる可能性があるので自動解決\n",
        "LON_COL = pick_first_existing(train, LON_CANDIDATES)\n",
        "LAT_COL = pick_first_existing(train, LAT_CANDIDATES)\n",
        "ensure_required_columns(test, [LON_COL, LAT_COL], \"test\")  # test側にも同名がある前提で確認\n",
        "\n",
        "# 時間列を追加（Step2/3/4で使用）\n",
        "train = add_time_columns(train)\n",
        "test  = add_time_columns(test)\n",
        "\n",
        "# distance列（Step2で NaNフラグ+大きな定数埋め の対象）\n",
        "DISTANCE_COLS = get_distance_cols(train)\n",
        "# train/testで一致しているかも早期に確認（完成度）\n",
        "missing_in_test = sorted(list(set(DISTANCE_COLS) - set(test.columns)))\n",
        "if len(missing_in_test) > 0:\n",
        "    raise KeyError(f\"[test] missing some distance columns present in train: {missing_in_test[:30]} ... total={len(missing_in_test)}\")\n",
        "\n",
        "# =========================================================\n",
        "# Step3/4で使う“分割マスク”の土台（ここでは定義だけ）\n",
        "# =========================================================\n",
        "# building_type が mansion/house 以外の表記なら、ここで気づけるようにしておく\n",
        "BUILDING_TYPES_TRAIN = train[BUILDING_TYPE_COL].astype(str).value_counts()\n",
        "BUILDING_TYPES_TEST  = test[BUILDING_TYPE_COL].astype(str).value_counts()\n",
        "\n",
        "print(\"train shape:\", train.shape, \" test shape:\", test.shape)\n",
        "print(\"lon/lat cols:\", LON_COL, LAT_COL)\n",
        "print(\"target_ym range train:\", int(train[YM_COL].min()), \"->\", int(train[YM_COL].max()))\n",
        "print(\"target_ym range test :\", int(test[YM_COL].min()),  \"->\", int(test[YM_COL].max()))\n",
        "print(\"num distance cols:\", len(DISTANCE_COLS))\n",
        "print(\"building_type(train):\")\n",
        "display(BUILDING_TYPES_TRAIN.head(20))\n",
        "print(\"building_type(test):\")\n",
        "display(BUILDING_TYPES_TEST.head(20))"
      ],
      "metadata": {
        "id": "5GX6zgeQqr9W",
        "outputId": "aa8787f7-7587-44ab-cbc8-ea60cfdecf40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (363924, 152)  test shape: (112437, 152)\n",
            "lon/lat cols: lon lat\n",
            "target_ym range train: 201901 -> 202207\n",
            "target_ym range test : 202301 -> 202307\n",
            "num distance cols: 11\n",
            "building_type(train):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "building_type\n",
              "1      194587\n",
              "4      153456\n",
              "999     14313\n",
              "5         468\n",
              "8         358\n",
              "15        274\n",
              "9         196\n",
              "901       126\n",
              "3          61\n",
              "2          37\n",
              "902        36\n",
              "14          7\n",
              "10          2\n",
              "12          1\n",
              "6           1\n",
              "11          1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>building_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>194587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>153456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>14313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>901</th>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building_type(test):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "building_type\n",
              "1      58650\n",
              "4      48594\n",
              "999     4756\n",
              "5        157\n",
              "8         80\n",
              "15        70\n",
              "9         47\n",
              "901       42\n",
              "3         17\n",
              "2         10\n",
              "902       10\n",
              "11         2\n",
              "10         1\n",
              "6          1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>building_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>4756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>901</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>902</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2) 特徴量作成\n",
        "#   - distance: NaNフラグ + 大きな定数埋め\n",
        "#   - log距離\n",
        "#   - 時系列補助特徴\n",
        "# =========================================================\n",
        "\n",
        "# -------------------------\n",
        "# コピー（破壊的変更を避ける）\n",
        "# -------------------------\n",
        "train_feat = train.copy()\n",
        "test_feat  = test.copy()"
      ],
      "metadata": {
        "id": "lSMvSRsVqs4T"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2-1. distance 特徴量\n",
        "#   ・NaN = 「一定距離内に存在しない」\n",
        "#   ・情報なのでフラグ化\n",
        "#   ・距離自体は大きな定数で埋める\n",
        "# =========================================================\n",
        "\n",
        "DIST_FILL_VALUES = {}  # Step3/4で再現できるよう保存\n",
        "\n",
        "for c in DISTANCE_COLS:\n",
        "    # ---- NaNフラグ\n",
        "    train_feat[f\"{c}_is_nan\"] = train_feat[c].isna().astype(\"int8\")\n",
        "    test_feat[f\"{c}_is_nan\"]  = test_feat[c].isna().astype(\"int8\")\n",
        "\n",
        "    # ---- 埋め値（trainの分位点で固定）\n",
        "    fill_value = train_feat[c].quantile(DIST_FILL_QUANTILE)\n",
        "    DIST_FILL_VALUES[c] = fill_value\n",
        "\n",
        "    train_feat[c] = train_feat[c].fillna(fill_value)\n",
        "    test_feat[c]  = test_feat[c].fillna(fill_value)\n",
        "\n",
        "    # ---- log距離（右裾対策）\n",
        "    train_feat[f\"{c}_log\"] = np.log1p(train_feat[c])\n",
        "    test_feat[f\"{c}_log\"]  = np.log1p(test_feat[c])"
      ],
      "metadata": {
        "id": "pRiaY6GRqw4O"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2-2. 時系列特徴（README準拠：掲載時期ズレ対策）\n",
        "# =========================================================\n",
        "\n",
        "# year / month / elapsed_months は Step1 ですでに作成済み\n",
        "# 追加で「周期性」を与える\n",
        "train_feat[\"month_sin\"] = np.sin(2 * np.pi * train_feat[\"month\"] / 12)\n",
        "train_feat[\"month_cos\"] = np.cos(2 * np.pi * train_feat[\"month\"] / 12)\n",
        "\n",
        "test_feat[\"month_sin\"] = np.sin(2 * np.pi * test_feat[\"month\"] / 12)\n",
        "test_feat[\"month_cos\"] = np.cos(2 * np.pi * test_feat[\"month\"] / 12)"
      ],
      "metadata": {
        "id": "-XyIF5coL0Iy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2-3. 建物年数系（壊れにくい最小構成）\n",
        "# =========================================================\n",
        "\n",
        "DATE_COLS = [\n",
        "    \"building_create_date\",\n",
        "    \"building_modify_date\"\n",
        "]\n",
        "\n",
        "for col in DATE_COLS:\n",
        "    if col in train_feat.columns:\n",
        "        train_feat[col] = pd.to_datetime(train_feat[col], errors=\"coerce\")\n",
        "        test_feat[col]  = pd.to_datetime(test_feat[col],  errors=\"coerce\")\n",
        "\n",
        "# 築年数（存在する場合のみ）\n",
        "if \"building_create_date\" in train_feat.columns:\n",
        "    train_feat[\"building_age\"] = train_feat[\"year\"] - train_feat[\"building_create_date\"].dt.year\n",
        "    test_feat[\"building_age\"]  = test_feat[\"year\"]  - test_feat[\"building_create_date\"].dt.year\n",
        "\n",
        "# マイナスや異常値を防ぐ\n",
        "if \"building_age\" in train_feat.columns:\n",
        "    train_feat[\"building_age\"] = train_feat[\"building_age\"].clip(lower=0)\n",
        "    test_feat[\"building_age\"]  = test_feat[\"building_age\"].clip(lower=0)"
      ],
      "metadata": {
        "id": "sUXL1k5Iqz2W"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2-4. カテゴリ列の整理（Step3でそのまま使える形）\n",
        "# =========================================================\n",
        "\n",
        "# LightGBMに渡す予定のカテゴリ列\n",
        "CATEGORICAL_COLS = []\n",
        "\n",
        "if BUILDING_TYPE_COL in train_feat.columns:\n",
        "    CATEGORICAL_COLS.append(BUILDING_TYPE_COL)\n",
        "    train_feat[BUILDING_TYPE_COL] = train_feat[BUILDING_TYPE_COL].astype(\"category\")\n",
        "    test_feat[BUILDING_TYPE_COL]  = test_feat[BUILDING_TYPE_COL].astype(\"category\")"
      ],
      "metadata": {
        "id": "OQWjRqnZq3mu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2-5. 数値列の最終ガード（inf / -inf / NaN）\n",
        "# =========================================================\n",
        "\n",
        "NUMERIC_COLS = train_feat.select_dtypes(include=[np.number]).columns.tolist()\n",
        "NUMERIC_COLS = [c for c in NUMERIC_COLS if c != TARGET_COL]\n",
        "\n",
        "def final_numeric_guard(df: pd.DataFrame, num_cols: list[str]) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df[num_cols] = (\n",
        "        df[num_cols]\n",
        "        .replace([np.inf, -np.inf], np.nan)\n",
        "        .fillna(0)\n",
        "    )\n",
        "    return df\n",
        "\n",
        "train_feat = final_numeric_guard(train_feat, NUMERIC_COLS)\n",
        "test_feat  = final_numeric_guard(test_feat,  NUMERIC_COLS)"
      ],
      "metadata": {
        "id": "YldeUXEiq5nO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2-6. Step3/4 用の列リストを確定\n",
        "# =========================================================\n",
        "\n",
        "FEATURE_COLS = [\n",
        "    c for c in train_feat.columns\n",
        "    if c not in [TARGET_COL]\n",
        "    and c in test_feat.columns\n",
        "]\n",
        "\n",
        "print(\"num features:\", len(FEATURE_COLS))\n",
        "print(\"sample feature cols:\", FEATURE_COLS[:20])"
      ],
      "metadata": {
        "id": "7re7RBC_q7ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e38ad5-eb3f-4cc0-d300-73439b3f1872"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num features: 176\n",
            "sample feature cols: ['target_ym', 'building_id', 'building_status', 'building_create_date', 'building_modify_date', 'building_type', 'building_name', 'building_name_ruby', 'homes_building_name', 'homes_building_name_ruby', 'unit_count', 'full_address', 'lon', 'lat', 'building_structure', 'total_floor_area', 'building_area', 'floor_count', 'basement_floor_count', 'year_built']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3) モデル作成（完成度重視）\n",
        "#   - 時系列 valid（例：2022）で検証可能な形にする\n",
        "#   - Step4で必要な変数を全てここで確定させる\n",
        "# =========================================================\n",
        "\n",
        "import lightgbm as lgb\n"
      ],
      "metadata": {
        "id": "sYz5h0qpJPri"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3-0. 整合性チェック（Step2の成果物が揃っているか）\n",
        "# =========================================================\n",
        "required_step2_vars = [\"train_feat\", \"test_feat\", \"FEATURE_COLS\", \"CATEGORICAL_COLS\"]\n",
        "for v in required_step2_vars:\n",
        "    if v not in globals():\n",
        "        raise NameError(f\"Missing required variable from Step2: {v}\")\n",
        "\n",
        "# targetの存在確認\n",
        "if TARGET_COL not in train_feat.columns:\n",
        "    raise KeyError(f\"train_feat missing target column: {TARGET_COL}\")"
      ],
      "metadata": {
        "id": "QR2D8BTps1eT"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3-1. 学習行列の作成（Step4でそのまま使う）\n",
        "# =========================================================\n",
        "X_train = train_feat[FEATURE_COLS].copy()\n",
        "y_train = train_feat[TARGET_COL].astype(float).copy()\n",
        "\n",
        "X_test  = test_feat[FEATURE_COLS].copy()\n",
        "\n",
        "# LightGBMに渡すカテゴリ列（存在するものだけ）\n",
        "CAT_COLS = [c for c in CATEGORICAL_COLS if c in X_train.columns]\n",
        "for c in CAT_COLS:\n",
        "    X_train[c] = X_train[c].astype(\"category\")\n",
        "    X_test[c]  = X_test[c].astype(\"category\")\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
        "print(\"num cat cols:\", len(CAT_COLS), CAT_COLS[:10])"
      ],
      "metadata": {
        "id": "XSH3UlBQs63P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9527f92-8c24-485a-9a22-6793258edbbe"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (363924, 176) X_test: (112437, 176)\n",
            "num cat cols: 1 ['building_type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3-2. 時系列 valid の作成（README準拠：過去→未来）\n",
        "#   デフォルトは 2022 を valid にする\n",
        "# =========================================================\n",
        "VALID_YEAR = 2022\n",
        "\n",
        "if \"year\" not in train_feat.columns:\n",
        "    raise KeyError(\"train_feat must have 'year' (created in Step1)\")\n",
        "\n",
        "valid_mask = (train_feat[\"year\"] == VALID_YEAR)\n",
        "train_mask = (train_feat[\"year\"] < VALID_YEAR)\n",
        "\n",
        "if valid_mask.sum() == 0:\n",
        "    raise ValueError(f\"No rows found for VALID_YEAR={VALID_YEAR}. Check train_feat['year'].\")\n",
        "\n",
        "if train_mask.sum() == 0:\n",
        "    raise ValueError(f\"No training rows found for year < {VALID_YEAR}. Check train_feat['year'].\")\n",
        "\n",
        "print(\"train rows:\", int(train_mask.sum()), \" valid rows:\", int(valid_mask.sum()))"
      ],
      "metadata": {
        "id": "Vhm36O-TGdCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6fe662-094a-4b0b-eff4-92e3fd7ab995"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train rows: 274358  valid rows: 89566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_numeric_features(df):\n",
        "    return df.select_dtypes(include=[np.number, bool])\n",
        "\n",
        "X_train_num = select_numeric_features(X_train)\n",
        "X_test_num  = select_numeric_features(X_test)\n",
        "\n",
        "print(\"使用特徴量数:\", X_train_num.shape[1])\n",
        "\n",
        "# =========================\n",
        "# 2. 念のため NaN / inf をガード（LightGBM的には必須ではないが安全）\n",
        "# =========================\n",
        "def final_numeric_guard(df):\n",
        "    df = df.copy()\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "X_train_num = final_numeric_guard(X_train_num)\n",
        "X_test_num  = final_numeric_guard(X_test_num)\n"
      ],
      "metadata": {
        "id": "DtcQjv4R7tiN",
        "outputId": "6d5092ba-90b9-4d29-9b11-64d3363da13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[drop non-numeric cols] 44 columns\n",
            "['building_create_date', 'building_modify_date', 'building_name', 'homes_building_name', 'homes_building_name_ruby', 'full_address', 'land_seigen', 'reform_exterior', 'reform_exterior_other', 'reform_common_area', 'building_tag_id', 'unit_name', 'reform_place', 'reform_place_other', 'reform_wet_area', 'reform_wet_area_other', 'reform_interior', 'reform_interior_other', 'reform_etc', 'renovation_date']\n",
            "[drop non-numeric cols] 45 columns\n",
            "['building_create_date', 'building_modify_date', 'building_name', 'homes_building_name', 'homes_building_name_ruby', 'full_address', 'land_seigen', 'reform_exterior', 'reform_exterior_other', 'reform_common_area', 'building_tag_id', 'unit_name', 'reform_place', 'reform_place_other', 'reform_wet_area', 'reform_wet_area_other', 'reform_interior', 'reform_interior_other', 'reform_etc', 'renovation_date']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "float64     103\n",
              "int64        11\n",
              "int8         11\n",
              "Int64         4\n",
              "Float64       2\n",
              "category      1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>float64</th>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>int64</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>int8</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Int64</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Float64</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3-3. 学習関数（log1pで学習、expで戻す）\n",
        "#   ※評価はStep4でMAPEなど多角的に行う\n",
        "# =========================================================\n",
        "def train_lgb_model(X_tr, y_tr, X_va, y_va):\n",
        "    params = {\n",
        "        \"objective\": \"regression\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"boosting_type\": \"gbdt\",\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"num_leaves\": 31,\n",
        "        \"feature_fraction\": 0.8,\n",
        "        \"bagging_fraction\": 0.8,\n",
        "        \"bagging_freq\": 1,\n",
        "        \"seed\": 42,\n",
        "        \"verbosity\": -1,\n",
        "    }\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, y_tr)\n",
        "    lgb_valid = lgb.Dataset(X_va, y_va, reference=lgb_train)\n",
        "\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        lgb_train,\n",
        "        valid_sets=[lgb_train, lgb_valid],\n",
        "        num_boost_round=3000,\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100),\n",
        "            lgb.log_evaluation(200),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7Comaq9hqQ0U"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3-4. 単一モデル or タイプ別モデル（切替可能）\n",
        "#   - まずは安定な「単一モデル」をデフォルトにする\n",
        "#   - あとで必要ならタイプ別に切り替え可能\n",
        "# =========================================================\n",
        "USE_TYPE_SPLIT = False  # まずは False 推奨（完成度・安定性優先）\n",
        "\n",
        "MODELS = {}  # Step4で使う\n",
        "\n",
        "# Step4で使う予測保持（raw）\n",
        "oof_pred_raw = np.full(len(train_feat), np.nan, dtype=float)\n",
        "test_pred_raw = np.zeros(len(test_feat), dtype=float)\n",
        "\n",
        "def predict_raw(model: lgb.Booster, X: pd.DataFrame) -> np.ndarray:\n",
        "    # log1p学習 → expm1で戻す\n",
        "    pred_log = model.predict(X, num_iteration=model.best_iteration)\n",
        "    pred = np.expm1(pred_log)\n",
        "    return pred\n",
        "\n",
        "if not USE_TYPE_SPLIT:\n",
        "    # ---- 単一モデル ----\n",
        "    model_all = train_lgb_model(\n",
        "        X_train_num.loc[train_mask],\n",
        "        y_train.loc[train_mask],\n",
        "        X_train_num.loc[valid_mask],\n",
        "        y_train.loc[valid_mask],\n",
        "    )\n",
        "    MODELS[\"all\"] = model_all\n",
        "\n",
        "    # valid予測（OOFの一部）\n",
        "    oof_pred_raw[valid_mask.values] = predict_raw(model_all, X_train.loc[valid_mask])\n",
        "\n",
        "    # test予測\n",
        "    y_test_pred = model_all.predict(X_test_num)\n",
        "\n",
        "else:\n",
        "    # ---- building_type 別モデル ----\n",
        "    if BUILDING_TYPE_COL not in train_feat.columns:\n",
        "        raise KeyError(f\"USE_TYPE_SPLIT=True requires {BUILDING_TYPE_COL}\")\n",
        "\n",
        "    for t in sorted(train_feat[BUILDING_TYPE_COL].astype(str).unique()):\n",
        "        tr_t = train_mask & (train_feat[BUILDING_TYPE_COL].astype(str) == t)\n",
        "        va_t = valid_mask & (train_feat[BUILDING_TYPE_COL].astype(str) == t)\n",
        "\n",
        "        if tr_t.sum() == 0 or va_t.sum() == 0:\n",
        "            print(f\"[skip] type={t} has tr={int(tr_t.sum())} va={int(va_t.sum())}\")\n",
        "            continue\n",
        "\n",
        "        model_t = train_lgb_model(\n",
        "            X_train.loc[tr_t], y_train.loc[tr_t],\n",
        "            X_train.loc[va_t], y_train.loc[va_t],\n",
        "            cat_cols=CAT_COLS,\n",
        "            seed=SEED + (hash(t) % 1000)\n",
        "        )\n",
        "        MODELS[t] = model_t\n",
        "\n",
        "        oof_pred_raw[va_t.values] = predict_raw(model_t, X_train.loc[va_t])\n",
        "\n",
        "        # test側も同じtypeのみ予測して埋める\n",
        "        te_t = (test_feat[BUILDING_TYPE_COL].astype(str) == t)\n",
        "        if te_t.sum() > 0:\n",
        "            test_pred_raw[te_t.values] = predict_raw(model_t, X_test_num.loc[te_t])"
      ],
      "metadata": {
        "id": "RLzwmUKeqUy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "e5e78e5f-b859-43a3-a8a4-bae534895bd2"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: building_create_date: datetime64[ns], building_modify_date: datetime64[ns], building_name: object, homes_building_name: object, homes_building_name_ruby: object, full_address: object, land_seigen: object, reform_exterior: object, reform_exterior_other: object, reform_common_area: object, building_tag_id: object, unit_name: object, reform_place: object, reform_place_other: object, reform_wet_area: object, reform_wet_area_other: object, reform_interior: object, reform_interior_other: object, reform_etc: object, renovation_date: object, renovation_etc: object, unit_tag_id: object, snapshot_create_date: object, new_date: object, snapshot_modify_date: object, timelimit_date: object, empty_contents: object, addr2_name: object, addr3_name: object, rosen_name1: object, eki_name1: object, bus_stop1: object, rosen_name2: object, eki_name2: object, bus_stop2: object, traffic_other: object, money_sonota_str1: object, money_sonota_str2: object, money_sonota_str3: object, parking_memo: object, school_ele_name: object, school_jun_name: object, est_other_name: object, statuses: object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1996275654.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mUSE_TYPE_SPLIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# ---- 単一モデル ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     model_all = train_lgb_model(\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1796896498.py\u001b[0m in \u001b[0;36mtrain_lgb_model\u001b[0;34m(X_tr, y_tr, X_va, y_va, cat_cols, seed)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_va_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     model = lgb.train(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3654\u001b[0m                 )\n\u001b[1;32m   3655\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3656\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2588\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m                 \u001b[0;31m# create train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m                 self._lazy_init(\n\u001b[0m\u001b[1;32m   2591\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m                     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2121\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m             data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n\u001b[0m\u001b[1;32m   2124\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                 \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     return (\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0m_pandas_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_pandas_to_numpy\u001b[0;34m(data, target_dtype)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"np.typing.DTypeLike\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m ) -> np.ndarray:\n\u001b[0;32m--> 814\u001b[0;31m     \u001b[0m_check_for_bad_pandas_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;31m# most common case (no nullable dtypes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[0;34m(pandas_dtypes_series)\u001b[0m\n\u001b[1;32m    803\u001b[0m     ]\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbad_pandas_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0;34mf\"pandas dtypes must be int, float or bool.\\nFields with bad pandas dtypes: {', '.join(bad_pandas_dtypes)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: building_create_date: datetime64[ns], building_modify_date: datetime64[ns], building_name: object, homes_building_name: object, homes_building_name_ruby: object, full_address: object, land_seigen: object, reform_exterior: object, reform_exterior_other: object, reform_common_area: object, building_tag_id: object, unit_name: object, reform_place: object, reform_place_other: object, reform_wet_area: object, reform_wet_area_other: object, reform_interior: object, reform_interior_other: object, reform_etc: object, renovation_date: object, renovation_etc: object, unit_tag_id: object, snapshot_create_date: object, new_date: object, snapshot_modify_date: object, timelimit_date: object, empty_contents: object, addr2_name: object, addr3_name: object, rosen_name1: object, eki_name1: object, bus_stop1: object, rosen_name2: object, eki_name2: object, bus_stop2: object, traffic_other: object, money_sonota_str1: object, money_sonota_str2: object, money_sonota_str3: object, parking_memo: object, school_ele_name: object, school_jun_name: object, est_other_name: object, statuses: object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3-5. Step4への受け渡し（列として保存）\n",
        "# =========================================================\n",
        "train_feat[\"pred_valid_raw\"] = oof_pred_raw   # valid年（例：2022）だけ値が入り、それ以外はNaN\n",
        "test_feat[\"pred_test_raw\"]   = test_pred_raw  # test全行\n",
        "\n",
        "PRED_VALID_COL = \"pred_valid_raw\"\n",
        "PRED_TEST_COL  = \"pred_test_raw\"\n",
        "\n",
        "print(\"[OK] Step3 artifacts ready:\")\n",
        "print(\" - MODELS keys:\", list(MODELS.keys())[:10])\n",
        "print(\" - train_feat[PRED_VALID_COL] non-null:\", int(np.isfinite(train_feat[PRED_VALID_COL]).sum()))\n",
        "print(\" - test_feat[PRED_TEST_COL] shape:\", test_feat[PRED_TEST_COL].shape)"
      ],
      "metadata": {
        "id": "rGud5_oyqXXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4) 受け渡し検証・可視化・後処理・提出（完成度重視）\n",
        "#  - 1/2/3/4 の整合性を最初に厳密チェック\n",
        "#  - VALID_YEAR(=2022)で多角的検証\n",
        "#  - NaNフラグ（distance）に関する診断\n",
        "#  - 後処理（低価格補正など）を「改善したか」まで確認\n",
        "#  - submit.csv を作成\n",
        "# =========================================================\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "g_ByR_IU8bly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-0. 整合性チェック\n",
        "# =========================================================\n",
        "def assert_pipeline_integrity():\n",
        "    # Step1\n",
        "    for v in [\"train\", \"test\", \"ID_COL\", \"TARGET_COL\", \"YM_COL\", \"BUILDING_TYPE_COL\",\n",
        "              \"LON_COL\", \"LAT_COL\", \"DISTANCE_COLS\", \"DIST_FILL_QUANTILE\"]:\n",
        "        if v not in globals():\n",
        "            raise NameError(f\"Missing from Step1: {v}\")\n",
        "\n",
        "    # Step2\n",
        "    for v in [\"train_feat\", \"test_feat\", \"FEATURE_COLS\", \"CATEGORICAL_COLS\", \"DIST_FILL_VALUES\"]:\n",
        "        if v not in globals():\n",
        "            raise NameError(f\"Missing from Step2: {v}\")\n",
        "\n",
        "    # Step3\n",
        "    for v in [\"X_train\", \"y_train\", \"X_test\", \"MODELS\", \"valid_mask\", \"train_mask\",\n",
        "              \"PRED_VALID_COL\", \"PRED_TEST_COL\"]:\n",
        "        if v not in globals():\n",
        "            raise NameError(f\"Missing from Step3: {v}\")\n",
        "\n",
        "    # 列存在チェック\n",
        "    must_train_cols = [ID_COL, TARGET_COL, YM_COL, \"year\", \"month\", \"elapsed_months\", BUILDING_TYPE_COL, PRED_VALID_COL]\n",
        "    must_test_cols  = [ID_COL, YM_COL, \"year\", \"month\", \"elapsed_months\", BUILDING_TYPE_COL, PRED_TEST_COL]\n",
        "    for c in must_train_cols:\n",
        "        if c not in train_feat.columns:\n",
        "            raise KeyError(f\"train_feat missing: {c}\")\n",
        "    for c in must_test_cols:\n",
        "        if c not in test_feat.columns:\n",
        "            raise KeyError(f\"test_feat missing: {c}\")\n",
        "\n",
        "    # FEATURE_COLS は train/test 両方に存在していること\n",
        "    missing_train = [c for c in FEATURE_COLS if c not in train_feat.columns]\n",
        "    missing_test  = [c for c in FEATURE_COLS if c not in test_feat.columns]\n",
        "    if missing_train:\n",
        "        raise KeyError(f\"train_feat missing FEATURE_COLS: {missing_train[:20]} ... total={len(missing_train)}\")\n",
        "    if missing_test:\n",
        "        raise KeyError(f\"test_feat missing FEATURE_COLS: {missing_test[:20]} ... total={len(missing_test)}\")\n",
        "\n",
        "    # 予測列の NaN 状態：valid年以外はNaNでもOK、valid年は全て埋まっていること\n",
        "    if train_feat.loc[valid_mask, PRED_VALID_COL].isna().any():\n",
        "        n = int(train_feat.loc[valid_mask, PRED_VALID_COL].isna().sum())\n",
        "        raise ValueError(f\"Validation predictions contain NaN: {n} rows in VALID_YEAR={VALID_YEAR}\")\n",
        "\n",
        "    # test予測は全行埋まっていること\n",
        "    if test_feat[PRED_TEST_COL].isna().any():\n",
        "        n = int(test_feat[PRED_TEST_COL].isna().sum())\n",
        "        raise ValueError(f\"Test predictions contain NaN: {n} rows\")\n",
        "\n",
        "    # 数値のinfチェック（重要）\n",
        "    def _has_inf(df, cols):\n",
        "        arr = df[cols].select_dtypes(include=[np.number]).to_numpy()\n",
        "        return np.isinf(arr).any()\n",
        "\n",
        "    if _has_inf(train_feat, FEATURE_COLS + [PRED_VALID_COL, TARGET_COL]):\n",
        "        raise ValueError(\"train_feat contains inf in features/preds/target\")\n",
        "    if _has_inf(test_feat, FEATURE_COLS + [PRED_TEST_COL]):\n",
        "        raise ValueError(\"test_feat contains inf in features/preds\")\n",
        "\n",
        "    print(\"[OK] Pipeline integrity check passed.\")\n",
        "\n",
        "assert_pipeline_integrity()"
      ],
      "metadata": {
        "id": "uDUK-gZf8e9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-1. 指標関数\n",
        "# =========================================================\n",
        "EPS = 1e-6\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    denom = np.maximum(np.abs(y_true), EPS)\n",
        "    return np.mean(np.abs(y_true - y_pred) / denom)\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
      ],
      "metadata": {
        "id": "81tyKwPSqZjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-2. VALID データセットの切り出し\n",
        "# =========================================================\n",
        "valid_df = train_feat.loc[valid_mask, :].copy()\n",
        "\n",
        "y_true = valid_df[TARGET_COL].values\n",
        "y_pred_raw = valid_df[PRED_VALID_COL].values\n",
        "\n",
        "print(\"\\n==== VALID METRICS (RAW) ====\")\n",
        "print(\"VALID_YEAR:\", VALID_YEAR)\n",
        "print(\"MAPE:\", mape(y_true, y_pred_raw))\n",
        "print(\"MAE :\", mae(y_true, y_pred_raw))\n",
        "print(\"RMSE:\", rmse(y_true, y_pred_raw))"
      ],
      "metadata": {
        "id": "aaM1NflE8neh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-3. 基本可視化（予測vs真値、残差、APE）\n",
        "# =========================================================\n",
        "def plot_pred_vs_true(y_true, y_pred, title):\n",
        "    plt.figure()\n",
        "    plt.scatter(y_true, y_pred, s=6, alpha=0.4)\n",
        "    mn = float(min(y_true.min(), y_pred.min()))\n",
        "    mx = float(max(y_true.max(), y_pred.max()))\n",
        "    plt.plot([mn, mx], [mn, mx])\n",
        "    plt.xlabel(\"true\")\n",
        "    plt.ylabel(\"pred\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def plot_hist(data, bins, title, xlabel):\n",
        "    plt.figure()\n",
        "    plt.hist(data, bins=bins)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(\"count\")\n",
        "    plt.show()\n",
        "\n",
        "plot_pred_vs_true(y_true, y_pred_raw, f\"VALID {VALID_YEAR}: Pred vs True (RAW)\")\n",
        "\n",
        "resid = y_pred_raw - y_true\n",
        "ape   = np.abs(resid) / np.maximum(np.abs(y_true), EPS)\n",
        "\n",
        "plot_hist(resid, bins=60, title=f\"VALID {VALID_YEAR}: Residual (pred-true)\", xlabel=\"residual\")\n",
        "plot_hist(ape,   bins=60, title=f\"VALID {VALID_YEAR}: APE\", xlabel=\"APE\")\n",
        "\n",
        "# ログ空間でも見る（外れの見え方が変わる）\n",
        "plot_pred_vs_true(np.log1p(y_true), np.log1p(y_pred_raw), f\"VALID {VALID_YEAR}: log1p(Pred) vs log1p(True)\")"
      ],
      "metadata": {
        "id": "TlSHkQ1hqcIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-4. 分解検証（改善の見通し用）\n",
        "#   - 月別 / 建物タイプ別 / 価格帯別（MAPEに効く）\n",
        "# =========================================================\n",
        "valid_df[\"ape\"] = ape\n",
        "\n",
        "# 月別\n",
        "month_summary = valid_df.groupby(\"month\").agg(\n",
        "    n=(TARGET_COL, \"size\"),\n",
        "    mape=(\"ape\", \"mean\"),\n",
        "    true_mean=(TARGET_COL, \"mean\"),\n",
        "    pred_mean=(PRED_VALID_COL, \"mean\"),\n",
        ")\n",
        "print(\"\\n---- VALID: month summary ----\")\n",
        "display(month_summary)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(month_summary.index.values, month_summary[\"mape\"].values, marker=\"o\")\n",
        "plt.xlabel(\"month\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(f\"VALID {VALID_YEAR}: MAPE by month\")\n",
        "plt.show()\n",
        "\n",
        "# building_type別\n",
        "type_summary = valid_df.groupby(BUILDING_TYPE_COL).agg(\n",
        "    n=(TARGET_COL, \"size\"),\n",
        "    mape=(\"ape\", \"mean\"),\n",
        "    true_mean=(TARGET_COL, \"mean\"),\n",
        "    pred_mean=(PRED_VALID_COL, \"mean\"),\n",
        ")\n",
        "print(\"\\n---- VALID: building_type summary ----\")\n",
        "display(type_summary)\n",
        "\n",
        "# 価格帯別（decile）\n",
        "valid_df[\"price_decile\"] = pd.qcut(valid_df[TARGET_COL], q=10, duplicates=\"drop\")\n",
        "price_summary = valid_df.groupby(\"price_decile\").agg(\n",
        "    n=(TARGET_COL, \"size\"),\n",
        "    mape=(\"ape\", \"mean\"),\n",
        "    true_mean=(TARGET_COL, \"mean\"),\n",
        "    pred_mean=(PRED_VALID_COL, \"mean\"),\n",
        ")\n",
        "print(\"\\n---- VALID: price decile summary ----\")\n",
        "display(price_summary)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(price_summary)), price_summary[\"mape\"].values, marker=\"o\")\n",
        "plt.xlabel(\"price decile (low -> high)\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(f\"VALID {VALID_YEAR}: MAPE by price decile\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h_hPUSZp3t27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-5. distance NaNフラグ診断（重大：今回の改善点の核心）\n",
        "#   - NaN群と非NaN群でMAPEがどう違うか\n",
        "#   - どの距離列のNaNが特に効いているかが見える\n",
        "# =========================================================\n",
        "nan_diag_rows = []\n",
        "for c in DISTANCE_COLS:\n",
        "    flag = f\"{c}_is_nan\"\n",
        "    if flag not in valid_df.columns:\n",
        "        continue\n",
        "\n",
        "    m_nan = valid_df[flag] == 1\n",
        "    m_non = valid_df[flag] == 0\n",
        "\n",
        "    # 両方の群が存在しない場合はスキップ\n",
        "    if m_nan.sum() == 0 or m_non.sum() == 0:\n",
        "        continue\n",
        "\n",
        "    y_nan_true = valid_df.loc[m_nan, TARGET_COL].values\n",
        "    y_nan_pred = valid_df.loc[m_nan, PRED_VALID_COL].values\n",
        "\n",
        "    y_non_true = valid_df.loc[m_non, TARGET_COL].values\n",
        "    y_non_pred = valid_df.loc[m_non, PRED_VALID_COL].values\n",
        "\n",
        "    nan_diag_rows.append({\n",
        "        \"distance_col\": c,\n",
        "        \"nan_ratio\": float(m_nan.mean()),\n",
        "        \"mape_nan\": float(mape(y_nan_true, y_nan_pred)),\n",
        "        \"mape_non\": float(mape(y_non_true, y_non_pred)),\n",
        "        \"delta_mape(nan-non)\": float(mape(y_nan_true, y_nan_pred) - mape(y_non_true, y_non_pred)),\n",
        "        \"n_nan\": int(m_nan.sum()),\n",
        "        \"n_non\": int(m_non.sum()),\n",
        "    })\n",
        "\n",
        "nan_diag = pd.DataFrame(nan_diag_rows).sort_values(\"delta_mape(nan-non)\", ascending=False)\n",
        "print(\"\\n---- VALID: distance NaN diagnostic (top) ----\")\n",
        "display(nan_diag.head(30))\n",
        "\n",
        "# 代表的なものをプロット（上位5つ）\n",
        "topk = nan_diag.head(5)[\"distance_col\"].tolist()\n",
        "for c in topk:\n",
        "    flag = f\"{c}_is_nan\"\n",
        "    plt.figure()\n",
        "    grp = valid_df.groupby(flag)[\"ape\"].mean()\n",
        "    plt.bar(grp.index.astype(str), grp.values)\n",
        "    plt.title(f\"VALID {VALID_YEAR}: mean APE by {flag}\")\n",
        "    plt.xlabel(f\"{flag} (0=exists, 1=missing)\")\n",
        "    plt.ylabel(\"mean APE\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S9DZIyifHARW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-6. 外れケースの抽出（次の改善が見える）\n",
        "#   - APE上位を building_id で追える\n",
        "# =========================================================\n",
        "worst = valid_df[[ID_COL, YM_COL, BUILDING_TYPE_COL, TARGET_COL, PRED_VALID_COL, \"ape\"]].sort_values(\"ape\", ascending=False)\n",
        "print(\"\\n---- Worst 30 APE (VALID) ----\")\n",
        "display(worst.head(30))"
      ],
      "metadata": {
        "id": "QLivWOc7HFMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-7. Feature importance（次の改善の方向性）\n",
        "#   - 単一モデルなら all\n",
        "#   - type split なら各モデル\n",
        "# =========================================================\n",
        "def show_feature_importance(model, feature_cols, topn=40, title=\"feature importance\"):\n",
        "    imp = pd.DataFrame({\n",
        "        \"feature\": feature_cols,\n",
        "        \"gain\": model.feature_importance(importance_type=\"gain\")\n",
        "    }).sort_values(\"gain\", ascending=False).head(topn)\n",
        "\n",
        "    plt.figure(figsize=(8, max(6, topn * 0.22)))\n",
        "    plt.barh(imp[\"feature\"][::-1], imp[\"gain\"][::-1])\n",
        "    plt.xlabel(\"gain importance\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "    return imp\n",
        "\n",
        "if \"all\" in MODELS:\n",
        "    imp_all = show_feature_importance(MODELS[\"all\"], FEATURE_COLS, topn=40, title=\"Model(all): top gain importance\")\n",
        "    print(\"\\n---- Top features (all) ----\")\n",
        "    display(imp_all.head(25))\n",
        "else:\n",
        "    for k, mdl in MODELS.items():\n",
        "        imp_k = show_feature_importance(mdl, FEATURE_COLS, topn=30, title=f\"Model({k}): top gain importance\")\n",
        "        print(f\"\\n---- Top features ({k}) ----\")\n",
        "        display(imp_k.head(20))"
      ],
      "metadata": {
        "id": "NADEr7FhHHoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-8. 後処理（例：低価格帯補正）＋「改善したか」を検証\n",
        "#   ※ここはあなたの状況に応じて最適化ポイント\n",
        "# =========================================================\n",
        "LOW_TH = 9_000_000\n",
        "LOW_SCALE = 0.83\n",
        "\n",
        "def apply_low_price_scale(pred, th=LOW_TH, scale=LOW_SCALE):\n",
        "    pred2 = pred.copy().astype(float)\n",
        "    mask = pred2 <= th\n",
        "    pred2[mask] *= scale\n",
        "    return pred2\n",
        "\n",
        "y_pred_post = apply_low_price_scale(y_pred_raw)\n",
        "\n",
        "print(\"\\n==== VALID METRICS (POST: low-price scale) ====\")\n",
        "print(\"MAPE:\", mape(y_true, y_pred_post))\n",
        "print(\"MAE :\", mae(y_true, y_pred_post))\n",
        "print(\"RMSE:\", rmse(y_true, y_pred_post))\n",
        "\n",
        "plot_pred_vs_true(y_true, y_pred_post, f\"VALID {VALID_YEAR}: Pred vs True (POST)\")\n",
        "plot_hist(np.abs(y_pred_post - y_true)/np.maximum(np.abs(y_true), EPS), bins=60,\n",
        "          title=f\"VALID {VALID_YEAR}: APE (POST)\", xlabel=\"APE\")\n",
        "\n",
        "# 価格帯別に「後処理が効いたか」も見える化\n",
        "valid_df[\"ape_post\"] = np.abs(y_pred_post - y_true) / np.maximum(np.abs(y_true), EPS)\n",
        "price_post_summary = valid_df.groupby(\"price_decile\").agg(\n",
        "    mape_raw=(\"ape\", \"mean\"),\n",
        "    mape_post=(\"ape_post\", \"mean\"),\n",
        "    n=(\"ape\", \"size\")\n",
        ")\n",
        "print(\"\\n---- VALID: price decile (raw vs post) ----\")\n",
        "display(price_post_summary)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(price_post_summary)), price_post_summary[\"mape_raw\"].values, marker=\"o\", label=\"raw\")\n",
        "plt.plot(np.arange(len(price_post_summary)), price_post_summary[\"mape_post\"].values, marker=\"o\", label=\"post\")\n",
        "plt.xlabel(\"price decile (low -> high)\")\n",
        "plt.ylabel(\"MAPE\")\n",
        "plt.title(f\"VALID {VALID_YEAR}: MAPE by price decile (raw vs post)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2bmTqiuzHMCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-9. submit作成（最終）\n",
        "#   - building_id と money_room を出す\n",
        "#   - raw/post どちらを採用するかはここで決められる\n",
        "# =========================================================\n",
        "# ----------------------\n",
        "# test予測（X_test_num 使用）\n",
        "# ----------------------\n",
        "y_test_pred = model_all.predict(X_test_num)\n",
        "\n",
        "# testの後処理も同じものを適用\n",
        "test_pred_raw = y_test_pred\n",
        "test_pred_post = apply_low_price_scale(test_pred_raw)\n",
        "\n",
        "# 最終採用（まずは post を使う。必要なら raw に戻す）\n",
        "test_feat[\"pred_final\"] = test_pred_post\n",
        "\n",
        "# clip（価格として負値はありえない）\n",
        "test_feat[\"pred_final\"] = test_feat[\"pred_final\"].clip(lower=0)\n",
        "\n",
        "SUBMIT_PATH = DATA_DIR / \"submit.csv\"\n",
        "submit = test_feat[[ID_COL]].copy()\n",
        "submit[TARGET_COL] = test_feat[\"pred_final\"].values\n",
        "\n",
        "submit.to_csv(SUBMIT_PATH, index=False, encoding=\"utf-8\")\n",
        "print(f\"\\n[OK] saved submit: {SUBMIT_PATH}\")\n",
        "display(submit.head())\n"
      ],
      "metadata": {
        "id": "Nm2unO08HTc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4-10. 次の改善が見通せる「自動診断まとめ」\n",
        "# =========================================================\n",
        "print(\"\\n==== Next Improvement Hints (auto) ====\")\n",
        "\n",
        "# 1) 月別の弱点\n",
        "worst_month = month_summary[\"mape\"].idxmax()\n",
        "print(f\"- Worst month (valid): month={int(worst_month)}  mape={month_summary.loc[worst_month, 'mape']:.4f}\")\n",
        "\n",
        "# 2) 価格帯の弱点\n",
        "worst_decile = price_summary[\"mape\"].idxmax()\n",
        "print(f\"- Worst price decile (valid): {worst_decile}  mape={price_summary.loc[worst_decile, 'mape']:.4f}\")\n",
        "\n",
        "# 3) distance NaN が痛い列\n",
        "if len(nan_diag) > 0:\n",
        "    top_bad = nan_diag.head(5)[[\"distance_col\", \"nan_ratio\", \"delta_mape(nan-non)\"]]\n",
        "    print(\"- distance NaN impact (top 5):\")\n",
        "    display(top_bad)\n",
        "    print(\"  Action: deltaが大きい列は、log距離に加えて、距離のbin化（例：0-200m,200-500m,...）や相互作用を検討\")\n",
        "\n",
        "# 4) elapsed_months の重要度が低いなら\n",
        "if \"all\" in MODELS:\n",
        "    # 重要度表に elapsed_months があるか確認\n",
        "    if \"elapsed_months\" in imp_all[\"feature\"].values:\n",
        "        rank = int(np.where(imp_all[\"feature\"].values == \"elapsed_months\")[0][0] + 1)\n",
        "        print(f\"- elapsed_months is in top list (rank~{rank} within shown topn).\")\n",
        "    else:\n",
        "        print(\"- elapsed_months not in shown top importance.\")\n",
        "        print(\"  Action: 時間水準特徴（例：prefecture×year の平均価格など）を追加すると効く余地が大きい\")\n",
        "\n",
        "print(\"\\n[Recommended next experiments]\")\n",
        "print(\"1) USE_TYPE_SPLIT=True（building_type別モデル）を試す（CVで確認）\")\n",
        "print(\"2) distance列のbin化＋is_nanの相互作用（例：is_nan * elapsed_months）\")\n",
        "print(\"3) 時間水準特徴：地域（pref/市区町村）× year の統計量（平均・中央値）を安全に作る（リークなしの形で）\")"
      ],
      "metadata": {
        "id": "qAzGhUzyHV01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
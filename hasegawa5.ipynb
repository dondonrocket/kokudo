{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT6PsCdLgEjdBlBd2Sg96J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondonrocket/kokudo/blob/%E3%83%86%E3%82%B9%E3%83%88/hasegawa5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a7Wc9jfop15s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import lightgbm as lgb\n",
        "from shapely.geometry import Point\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. train/test 読み込み\n",
        "# =========================\n",
        "train = pd.read_csv(\"/content/train.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)\n",
        "test  = pd.read_csv(\"/content/test.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)"
      ],
      "metadata": {
        "id": "322pg9pCqBZs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0-1. 都道府県コードを追加\n",
        "# =========================\n",
        "train['prefecture_code'] = train['addr1_1']\n",
        "test['prefecture_code']  = test['addr1_1']\n",
        "\n",
        "# =========================\n",
        "# 0-2. 地域サンプル重み（地方を強める）\n",
        "# =========================\n",
        "weights = train['prefecture_code'].value_counts(normalize=True)\n",
        "train['sample_weight'] = train['prefecture_code'].map(lambda x: 1/weights[x])\n",
        "\n",
        "# =========================\n",
        "# 1. year_built（年 or 年月）を正規化\n",
        "# =========================\n",
        "def normalize_year_month(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "\n",
        "    x = float(x)\n",
        "    year = int(x)\n",
        "    month = round((x - year) * 100)\n",
        "\n",
        "    if 1 <= month <= 12:\n",
        "        return year + month / 12\n",
        "    else:\n",
        "        return float(year)\n",
        "\n",
        "for df in [train, test]:\n",
        "    df[\"year_built_adj\"] = (\n",
        "        pd.to_numeric(df[\"year_built\"], errors=\"coerce\")\n",
        "        .apply(normalize_year_month)\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# 3. 新耐震フラグ（1981年基準）\n",
        "# =========================\n",
        "\n",
        "def classify_seismic(ym):\n",
        "  if pd.isna(ym):\n",
        "      return -1\n",
        "  if ym >= 198106:\n",
        "      return 2\n",
        "  elif ym >= 195012:\n",
        "      return 1\n",
        "  else:\n",
        "      return 0\n",
        "\n",
        "for df in [train, test]:\n",
        "    df[\"seismic_class\"] = df[\"year_built_adj\"].apply(classify_seismic)\n",
        "\n",
        "# =========================\n",
        "# 2. 築年数（age）\n",
        "# =========================\n",
        "CURRENT_YEAR = 2023\n",
        "\n",
        "for df in [train, test]:\n",
        "    df[\"age\"] = (CURRENT_YEAR - df[\"year_built_adj\"]).clip(0, 100)\n",
        "    df[\"age_sq\"] = df[\"age\"] ** 2\n",
        "    df[\"age_log\"] = np.log1p(df[\"age\"])\n",
        "    df[\"age_x_seismic\"] = df[\"age\"] * df[\"seismic_class\"]\n",
        "\n",
        "# =========================\n",
        "# 4. house_area 欠損処理（建物タイプ別）\n",
        "# =========================\n",
        "for df in [train, test]:\n",
        "    if \"house_area\" in df.columns:\n",
        "        df[\"house_area\"] = pd.to_numeric(df[\"house_area\"], errors=\"coerce\")\n",
        "\n",
        "        for bt in df[\"building_type\"].dropna().unique():\n",
        "            median_area = df.loc[df[\"building_type\"] == bt, \"house_area\"].median()\n",
        "            df.loc[\n",
        "                (df[\"building_type\"] == bt) & (df[\"house_area\"].isna()),\n",
        "                \"house_area\"\n",
        "            ] = median_area\n",
        "\n",
        "        # 最終ガード\n",
        "        df[\"house_area\"] = df[\"house_area\"].fillna(df[\"house_area\"].median())\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 6. house_area前処理\n",
        "# =========================\n",
        "for df in [train, test]:\n",
        "    df[\"house_area\"] = pd.to_numeric(df[\"house_area\"], errors=\"coerce\")\n",
        "    df[\"house_area\"] = df[\"house_area\"].fillna(df[\"house_area\"].median())"
      ],
      "metadata": {
        "id": "qp2sdE_e7ruL",
        "outputId": "b9622a3d-5686-4464-a7ce-9b183a546fd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-223622846.py:72: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '71.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 駅乗降客数（2019年）\n",
        "# =========================\n",
        "df = pd.read_csv(\"S12-24_NumberOfPassengers_utf8.csv\")\n",
        "df_2019 = df[(df[\"S12_039\"]==1)&(df[\"S12_038\"]==1)]\n",
        "station_2019 = df_2019.groupby(\"S12_001c\", as_index=False).agg(passengers_2019=(\"S12_041\",\"sum\")).rename(columns={\"S12_001c\":\"station_code\"})\n"
      ],
      "metadata": {
        "id": "lSMvSRsVqs4T"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 3. 駅ポイント（lon / lat）\n",
        "# =========================\n",
        "station_point_gdf = gpd.read_file(\"/content/S12-24_NumberOfPassengers.geojson\")\n",
        "station_point_gdf[\"S12_001c\"] = station_point_gdf[\"S12_001c\"].astype(str)\n",
        "station_2019[\"station_code\"] = station_2019[\"station_code\"].astype(str)\n",
        "stations = station_point_gdf.merge(station_2019, left_on=\"S12_001c\", right_on=\"station_code\", how=\"left\")\n",
        "stations = stations.to_crs(epsg=3857)\n",
        "stations[\"geometry\"] = stations.geometry.centroid\n",
        "stations_gdf = stations[[\"S12_001c\",\"passengers_2019\",\"geometry\"]].copy()\n",
        "stations_gdf.crs = \"EPSG:3857\""
      ],
      "metadata": {
        "id": "pRiaY6GRqw4O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 駅特徴量作成関数\n",
        "# =========================\n",
        "def add_station_features(df, stations_gdf, radius=500):\n",
        "    df = df.copy()\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
        "\n",
        "    # 既存の index_right を削除\n",
        "    if \"index_right\" in gdf.columns:\n",
        "        gdf = gdf.drop(columns=[\"index_right\"])\n",
        "    if \"index_right\" in stations_gdf.columns:\n",
        "        stations_gdf = stations_gdf.drop(columns=[\"index_right\"])\n",
        "\n",
        "    joined = gpd.sjoin(gdf, stations_gdf, how=\"left\", predicate=\"dwithin\", distance=radius)\n",
        "\n",
        "    feat = joined.groupby(\"building_id\", as_index=False).agg(\n",
        "        **{\n",
        "            f\"station_passengers_{radius}m_sum\": (\"passengers_2019\",\"sum\"),\n",
        "            f\"station_passengers_{radius}m_max\": (\"passengers_2019\",\"max\"),\n",
        "            f\"station_passengers_{radius}m_mean\": (\"passengers_2019\",\"mean\")\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df = df.merge(feat, on=\"building_id\", how=\"left\")\n",
        "    for col in feat.columns:\n",
        "        if col != \"building_id\":\n",
        "          mean_val = df[col].mean()  # 全国平均\n",
        "          df[col] = df[col].fillna(mean_val)\n",
        "          df[col + \"_log\"] = np.log1p(df[col])\n",
        "    return df"
      ],
      "metadata": {
        "id": "sUXL1k5Iqz2W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# DID データ読み込み\n",
        "# =========================\n",
        "did_gdf = gpd.read_file(\"/content/A16-20_00_DID.shp\")\n",
        "\n",
        "# 人口・面積カラム\n",
        "DID_POP_COL  = \"A16_005\"\n",
        "DID_AREA_COL = \"A16_006\"\n",
        "\n",
        "# 密度\n",
        "did_gdf[\"DID_density\"] = did_gdf[DID_POP_COL] / (did_gdf[DID_AREA_COL] + 1e-6)\n",
        "\n",
        "# CRS統一\n",
        "did_gdf = did_gdf.to_crs(epsg=3857)\n",
        "\n",
        "#train / test を GeoDataFrame に変換\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=gpd.points_from_xy(train[\"lon\"], train[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=gpd.points_from_xy(test[\"lon\"], test[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "\n",
        "#KDTree用の座標準備\n",
        "# DIDポリゴンの代表点（centroid）\n",
        "did_coords = np.vstack([did_gdf.geometry.centroid.x, did_gdf.geometry.centroid.y]).T\n",
        "tree_did = KDTree(did_coords)\n",
        "\n",
        "#最近傍DIDを割り当てる関数\n",
        "def attach_DID_features(base_gdf, did_gdf, tree):\n",
        "    coords = np.vstack([\n",
        "        base_gdf.geometry.x,\n",
        "        base_gdf.geometry.y\n",
        "    ]).T\n",
        "\n",
        "    _, idx = tree.query(coords, k=1)\n",
        "\n",
        "    base_gdf[\"DID_population\"] = did_gdf.iloc[idx.flatten()][DID_POP_COL].values\n",
        "    base_gdf[\"DID_area\"]       = did_gdf.iloc[idx.flatten()][DID_AREA_COL].values\n",
        "    base_gdf[\"DID_density\"]    = did_gdf.iloc[idx.flatten()][\"DID_density\"].values\n",
        "\n",
        "    return base_gdf\n",
        "\n",
        "#train / test にDID付与\n",
        "train_gdf = attach_DID_features(train_gdf, did_gdf, tree_did)\n",
        "test_gdf  = attach_DID_features(test_gdf, did_gdf, tree_did)\n",
        "\n",
        "#geometryを落として DataFrame に戻す\n",
        "train = pd.DataFrame(train_gdf.drop(columns=\"geometry\"))\n",
        "test  = pd.DataFrame(test_gdf.drop(columns=\"geometry\"))\n",
        "\n",
        "#欠損処理\n",
        "for col in [\"DID_population\", \"DID_area\", \"DID_density\"]:\n",
        "    for df in [train, test]:\n",
        "        df[col] = df[col].fillna(df[col].mean())\n",
        "        df[col + \"_log\"] = np.log1p(df[col])\n",
        "\n",
        "#house_area × DID\n",
        "for df in [train, test]:\n",
        "    df[\"area_weighted_by_urban\"] = df[\"house_area\"] * (1 + df[\"DID_density_log\"])\n",
        "\n",
        "# -------------------------\n",
        "# 駅特徴量作成関数（全国対応）\n",
        "# -------------------------\n",
        "def add_station_features(df, stations_gdf, radius=500):\n",
        "    df = df.copy()\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df,\n",
        "        geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    ).to_crs(epsg=3857)\n",
        "\n",
        "    # sjoin\n",
        "    joined = gpd.sjoin(\n",
        "        gdf, stations_gdf, how=\"left\", predicate=\"dwithin\", distance=radius\n",
        "    )\n",
        "\n",
        "    # building_idで集計\n",
        "    feat = joined.groupby(\"building_id\", as_index=False).agg(\n",
        "        **{\n",
        "            f\"station_passengers_{radius}m_sum\": (\"passengers_2019\",\"sum\"),\n",
        "            f\"station_passengers_{radius}m_max\": (\"passengers_2019\",\"max\"),\n",
        "            f\"station_passengers_{radius}m_mean\": (\"passengers_2019\",\"mean\")\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df = df.merge(feat, on=\"building_id\", how=\"left\")\n",
        "\n",
        "    # 全国平均で補完＆ログ列作成\n",
        "    for col in [f\"station_passengers_{radius}m_sum\",\n",
        "                f\"station_passengers_{radius}m_max\",\n",
        "                f\"station_passengers_{radius}m_mean\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 0\n",
        "        df[col].fillna(df[col].mean(), inplace=True)\n",
        "        df[col + \"_log\"] = np.log1p(df[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "#特徴量に追加\n",
        "did_area_features = [\n",
        "    \"DID_population\",\n",
        "    \"DID_area\",\n",
        "    \"DID_density\",\n",
        "    \"DID_density_log\",\n",
        "    \"area_x_log_DID_density\",\n",
        "    \"area_weighted_by_urban\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "cgaNU8Hd4wWD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 5. train/testに駅特徴量付与\n",
        "# =========================\n",
        "for radius in [500,1000]:\n",
        "    train = add_station_features(train, stations_gdf, radius)\n",
        "    test  = add_station_features(test, stations_gdf, radius)"
      ],
      "metadata": {
        "id": "OQWjRqnZq3mu",
        "outputId": "8ce1bb72-b407-41ac-e616-b4659217dd82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n",
            "/tmp/ipython-input-3773243619.py:101: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. 地価公示データ\n",
        "# =========================\n",
        "land_gdf = gpd.read_file(\"/content/L01-23.geojson\").to_crs(epsg=4326)\n",
        "for df in [train,test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "train_gdf = gpd.GeoDataFrame(train, geometry=\"geometry\", crs=\"EPSG:4326\").to_crs(epsg=6668)\n",
        "test_gdf  = gpd.GeoDataFrame(test, geometry=\"geometry\", crs=\"EPSG:6668\").to_crs(epsg=6668)\n",
        "land_gdf  = land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "# KDTree\n",
        "land_xy = np.vstack([land_gdf.geometry.x.values, land_gdf.geometry.y.values]).T\n",
        "tree_land = KDTree(land_xy)\n",
        "land_prices = land_gdf['L01_006'].values\n",
        "\n",
        "def nearest_land_price_fast(pt, tree, land_prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return land_prices[idx[0][0]]\n",
        "\n",
        "train['final_land_price'] = train_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree_land, land_prices))\n",
        "test['final_land_price']  = test_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree_land, land_prices))\n",
        "\n",
        "# 欠損は全国平均で補完\n",
        "for df in [train, test]:\n",
        "    df[\"final_land_price\"].fillna(df[\"final_land_price\"].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "7re7RBC_q7ZC",
        "outputId": "bc56e1de-93c1-478d-8767-7716902f78bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-199428095.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"final_land_price\"].fillna(df[\"final_land_price\"].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. マンション/戸建てに分割\n",
        "# =========================\n",
        "train_mansion = train[train['building_type'] == 1].copy()\n",
        "train_house   = train[train['building_type'] == 4].copy()\n",
        "test_mansion  = test[test['building_type'] == 1].copy()\n",
        "test_house    = test[test['building_type'] == 4].copy()"
      ],
      "metadata": {
        "id": "QR2D8BTps1eT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 共通特徴量\n",
        "# =========================\n",
        "common_features = [\n",
        "    'target_ym','lon','lat',\n",
        "    'drugstore_distance','bank_distance','shopping_street_distance',\n",
        "    'parking_keiyaku','money_hoshou_company','free_rent_duration','free_rent_gen_timing',\n",
        "        'year_built_adj','age','seismic_class','age','age_sq','age_log','age_x_seismic'\n",
        "]\n",
        "\n",
        "mansion_features = common_features + [\n",
        "    'house_area','floor','room_count','total_units','building_structure','has_elevator','has_gym','maintenance_fee',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean',\"DID_density_log\",\"area_weighted_by_urban\"\n",
        "]\n",
        "\n",
        "house_features = common_features + [\n",
        "    'house_area','land_area','floor_count','room_count','building_structure',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean',\"DID_density_log\",\"area_weighted_by_urban\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "XSH3UlBQs63P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 学習用データ作成関数\n",
        "# =========================\n",
        "\n",
        "DROP_COLS = [\n",
        "    \"id\",\n",
        "    \"money_room\",\n",
        "    \"money_hoshou_company\",\n",
        "    \"sample_weight\"\n",
        "]\n",
        "\n",
        "def make_features(df):\n",
        "    return [\n",
        "        c for c in df.columns\n",
        "        if c not in DROP_COLS\n",
        "        and df[c].dtype != \"object\"\n",
        "    ]\n",
        "\n",
        "mansion_features = make_features(train_mansion)\n",
        "house_features   = make_features(train_house)\n",
        "\n",
        "def prepare_Xy(df, features, is_train=True):\n",
        "    X = df[[c for c in features if c in df.columns]].copy()\n",
        "\n",
        "    # geometry が紛れ込んでも必ず落とす\n",
        "    if \"geometry\" in X.columns:\n",
        "        X = X.drop(columns=[\"geometry\"])\n",
        "\n",
        "    # 数値型だけに限定（最終防衛ライン）\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "    if is_train:\n",
        "        y = np.log1p(df[\"money_room\"])\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "X_mansion, y_mansion = prepare_Xy(train_mansion, mansion_features)\n",
        "X_house, y_house     = prepare_Xy(train_house, house_features)\n",
        "\n",
        "X_test_mansion = test_mansion[mansion_features].copy()\n",
        "X_test_house   = test_house[house_features].copy()\n",
        "\n"
      ],
      "metadata": {
        "id": "7Comaq9hqQ0U"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 学習関数\n",
        "# =========================\n",
        "def train_lgb(X, y, sample_weight=None):\n",
        "    model = lgb.LGBMRegressor(\n",
        "        n_estimators=5000,\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=64,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        objective=\"fair\",\n",
        "        fair_c=0.1,\n",
        "        min_child_samples=20,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1\n",
        "    )\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    if sample_weight is not None:\n",
        "        w_train, w_valid = train_test_split(sample_weight, test_size=0.2, random_state=42)\n",
        "    else:\n",
        "        w_train = w_valid = None\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        sample_weight=w_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_sample_weight=[w_valid] if sample_weight is not None else None,\n",
        "        eval_metric=\"mape\",\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(200),\n",
        "            lgb.log_evaluation(200)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "RLzwmUKeqUy0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. モデル学習\n",
        "# =========================\n",
        "model_mansion = train_lgb(X_mansion, y_mansion, sample_weight=train_mansion['sample_weight'])\n",
        "model_house   = train_lgb(X_house, y_house, sample_weight=train_house['sample_weight'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGud5_oyqXXP",
        "outputId": "052c1f0c-b976-4b78-8a3a-2f0a00bdfc64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102123 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14831\n",
            "[LightGBM] [Info] Number of data points in the train set: 155669, number of used features: 109\n",
            "[LightGBM] [Info] Start training from score 16.734532\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's mape: 0.00856018\tvalid_0's fair: 0.00658296\n",
            "[400]\tvalid_0's mape: 0.00800346\tvalid_0's fair: 0.00600873\n",
            "[600]\tvalid_0's mape: 0.00775235\tvalid_0's fair: 0.00575608\n",
            "[800]\tvalid_0's mape: 0.00758445\tvalid_0's fair: 0.00558823\n",
            "[1000]\tvalid_0's mape: 0.00746004\tvalid_0's fair: 0.00546401\n",
            "[1200]\tvalid_0's mape: 0.00737258\tvalid_0's fair: 0.00537747\n",
            "[1400]\tvalid_0's mape: 0.00729838\tvalid_0's fair: 0.00530491\n",
            "[1600]\tvalid_0's mape: 0.00723796\tvalid_0's fair: 0.00524688\n",
            "[1800]\tvalid_0's mape: 0.00718054\tvalid_0's fair: 0.00519088\n",
            "[2000]\tvalid_0's mape: 0.00712569\tvalid_0's fair: 0.00513718\n",
            "[2200]\tvalid_0's mape: 0.0070814\tvalid_0's fair: 0.00509389\n",
            "[2400]\tvalid_0's mape: 0.00704286\tvalid_0's fair: 0.00505583\n",
            "[2600]\tvalid_0's mape: 0.00701735\tvalid_0's fair: 0.00503123\n",
            "[2800]\tvalid_0's mape: 0.00698576\tvalid_0's fair: 0.00500147\n",
            "[3000]\tvalid_0's mape: 0.00695851\tvalid_0's fair: 0.00497529\n",
            "[3200]\tvalid_0's mape: 0.00693182\tvalid_0's fair: 0.00495016\n",
            "[3400]\tvalid_0's mape: 0.0069069\tvalid_0's fair: 0.00492624\n",
            "[3600]\tvalid_0's mape: 0.00688516\tvalid_0's fair: 0.00490451\n",
            "[3800]\tvalid_0's mape: 0.00686726\tvalid_0's fair: 0.00488675\n",
            "[4000]\tvalid_0's mape: 0.00684854\tvalid_0's fair: 0.00486926\n",
            "[4200]\tvalid_0's mape: 0.00683018\tvalid_0's fair: 0.00485152\n",
            "[4400]\tvalid_0's mape: 0.00681618\tvalid_0's fair: 0.00483907\n",
            "[4600]\tvalid_0's mape: 0.00680019\tvalid_0's fair: 0.00482394\n",
            "[4800]\tvalid_0's mape: 0.00678702\tvalid_0's fair: 0.00481202\n",
            "[5000]\tvalid_0's mape: 0.00677338\tvalid_0's fair: 0.00479938\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00677338\tvalid_0's fair: 0.00479938\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077618 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12794\n",
            "[LightGBM] [Info] Number of data points in the train set: 122764, number of used features: 106\n",
            "[LightGBM] [Info] Start training from score 16.612198\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's mape: 0.0109305\tvalid_0's fair: 0.00927916\n",
            "[400]\tvalid_0's mape: 0.010227\tvalid_0's fair: 0.00849436\n",
            "[600]\tvalid_0's mape: 0.00984166\tvalid_0's fair: 0.00808823\n",
            "[800]\tvalid_0's mape: 0.0095763\tvalid_0's fair: 0.00781427\n",
            "[1000]\tvalid_0's mape: 0.0093769\tvalid_0's fair: 0.00761179\n",
            "[1200]\tvalid_0's mape: 0.00923281\tvalid_0's fair: 0.0074675\n",
            "[1400]\tvalid_0's mape: 0.0091113\tvalid_0's fair: 0.00734722\n",
            "[1600]\tvalid_0's mape: 0.00900292\tvalid_0's fair: 0.00724192\n",
            "[1800]\tvalid_0's mape: 0.00891086\tvalid_0's fair: 0.00715355\n",
            "[2000]\tvalid_0's mape: 0.00882853\tvalid_0's fair: 0.0070736\n",
            "[2200]\tvalid_0's mape: 0.0087523\tvalid_0's fair: 0.00699945\n",
            "[2400]\tvalid_0's mape: 0.0086849\tvalid_0's fair: 0.00693509\n",
            "[2600]\tvalid_0's mape: 0.00862881\tvalid_0's fair: 0.0068815\n",
            "[2800]\tvalid_0's mape: 0.00858201\tvalid_0's fair: 0.00683662\n",
            "[3000]\tvalid_0's mape: 0.00853085\tvalid_0's fair: 0.00678796\n",
            "[3200]\tvalid_0's mape: 0.00848509\tvalid_0's fair: 0.00674448\n",
            "[3400]\tvalid_0's mape: 0.00844527\tvalid_0's fair: 0.00670841\n",
            "[3600]\tvalid_0's mape: 0.00841179\tvalid_0's fair: 0.00667614\n",
            "[3800]\tvalid_0's mape: 0.00837337\tvalid_0's fair: 0.00663884\n",
            "[4000]\tvalid_0's mape: 0.008341\tvalid_0's fair: 0.00660853\n",
            "[4200]\tvalid_0's mape: 0.00831313\tvalid_0's fair: 0.00658298\n",
            "[4400]\tvalid_0's mape: 0.00827958\tvalid_0's fair: 0.00655157\n",
            "[4600]\tvalid_0's mape: 0.0082515\tvalid_0's fair: 0.0065262\n",
            "[4800]\tvalid_0's mape: 0.00822893\tvalid_0's fair: 0.00650635\n",
            "[5000]\tvalid_0's mape: 0.00820415\tvalid_0's fair: 0.00648454\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00820415\tvalid_0's fair: 0.00648454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. 学習時の列を保存\n",
        "# =========================\n",
        "cols_mansion = X_mansion.columns.tolist()\n",
        "cols_house   = X_house.columns.tolist()"
      ],
      "metadata": {
        "id": "g_ByR_IU8bly"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. test の列を学習時と完全一致させる\n",
        "# =========================\n",
        "X_test_mansion = X_test_mansion.reindex(\n",
        "    columns=cols_mansion,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "X_test_house = X_test_house.reindex(\n",
        "    columns=cols_house,\n",
        "    fill_value=0\n",
        ")"
      ],
      "metadata": {
        "id": "uDUK-gZf8e9W"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 低価格帯補正つき予測\n",
        "# =========================\n",
        "LOW_TH_MANSION = 9_000_000\n",
        "LOW_TH_HOUSE   = 9_000_000\n",
        "\n",
        "LOW_SCALE_MANSION = 0.83\n",
        "LOW_SCALE_HOUSE   = 0.83\n",
        "\n",
        "\n",
        "def predict_with_low_scale(model, X, low_th, low_scale):\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # まず予測値側をガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=20,   # log空間での上限\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # log → 元スケール\n",
        "    y_pred = np.expm1(y_pred)\n",
        "\n",
        "    # 再度ガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=1e9,\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # 下限クリップ\n",
        "    y_pred = np.clip(y_pred, 1, 1e9)\n",
        "\n",
        "    # 低価格帯補正\n",
        "    mask_low = y_pred <= low_th\n",
        "    y_pred[mask_low] *= low_scale\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_mansion = predict_with_low_scale(\n",
        "    model_mansion,\n",
        "    X_test_mansion,\n",
        "    LOW_TH_MANSION,\n",
        "    LOW_SCALE_MANSION\n",
        ")\n",
        "\n",
        "y_pred_test_house = predict_with_low_scale(\n",
        "    model_house,\n",
        "    X_test_house,\n",
        "    LOW_TH_HOUSE,\n",
        "    LOW_SCALE_HOUSE\n",
        ")"
      ],
      "metadata": {
        "id": "81tyKwPSqZjT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. test DataFrame に書き戻す\n",
        "# =========================\n",
        "test.loc[test_mansion.index, \"money_room\"] = y_pred_test_mansion\n",
        "test.loc[test_house.index,   \"money_room\"] = y_pred_test_house\n",
        "\n",
        "mask_other = test[\"money_room\"].isna()\n",
        "\n",
        "X_other = test.loc[mask_other].reindex(columns=cols_mansion, fill_value=0)\n",
        "\n",
        "test.loc[mask_other, \"money_room\"] = predict_with_low_scale(\n",
        "    model_mansion, X_other, LOW_TH_MANSION, LOW_SCALE_MANSION\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 8. 最終ガード（超重要）\n",
        "# =========================\n",
        "test[\"money_room\"] = (\n",
        "    test[\"money_room\"]\n",
        "    .replace([np.inf, -np.inf], np.nan)\n",
        "    .fillna(test[\"money_room\"].median())\n",
        "    .clip(1, 1e9)\n",
        ")"
      ],
      "metadata": {
        "id": "aaM1NflE8neh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. submit.csv 作成\n",
        "# =========================\n",
        "submit = test[[\"id\", \"money_room\"]].sort_values(\"id\")\n",
        "submit.to_csv(\"submit.csv\", index=False, header=False)\n",
        "\n",
        "print(\"submit.csv を出力しました\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlSHkQ1hqcIM",
        "outputId": "2c8fb4fc-4aee-445c-f639-67e554477bad"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit.csv を出力しました\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/submit.csv\")\n",
        "\n",
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_hPUSZp3t27",
        "outputId": "ee901e09-771b-4e57-f510-3769db2738d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPypmIFRoT4V5Zrhstgz+AP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondonrocket/kokudo/blob/%EF%BC%91%EF%BC%97%EF%BC%8E%EF%BC%90%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89base/16_2hasegawa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "a7Wc9jfop15s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import lightgbm as lgb\n",
        "from shapely.geometry import Point\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. train/test 読み込み\n",
        "# =========================\n",
        "train = pd.read_csv(\"/content/train.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)\n",
        "test  = pd.read_csv(\"/content/test.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)"
      ],
      "metadata": {
        "id": "322pg9pCqBZs"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. floor_count の異常値削除\n",
        "# =========================\n",
        "# 日本で一番高いマンションは64階なので70階以上は明らかに異常\n",
        "train = train.loc[train['floor_count'] <= 70]"
      ],
      "metadata": {
        "id": "xAFNw8K3O3Eu"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. グローバル設定\n",
        "# =========================\n",
        "#SEEDS = [42, 100, 202, 777, 999]\n",
        "SEEDS = [100]"
      ],
      "metadata": {
        "id": "1fz6nvePZZZl"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 都道府県地価調査（2023）\n",
        "# =========================\n",
        "pref_land_gdf = gpd.read_file(\"/content/L02-23.geojson\")\n",
        "\n",
        "# 念のため CRS 統一（地価公示と同じ）\n",
        "pref_land_gdf = pref_land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "# 調査価格\n",
        "PRICE_COL = \"L02_006\"\n",
        "\n",
        "pref_land_gdf = pref_land_gdf[\n",
        "    [\"geometry\", PRICE_COL]\n",
        "].rename(columns={\n",
        "    PRICE_COL: \"pref_land_price\"\n",
        "})\n",
        "\n",
        "#train / test を GeoDataFrame に変換\n",
        "for df in [train, test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=\"geometry\",\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=6668)\n",
        "\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=\"geometry\",\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=6668)\n",
        "\n",
        "# 都道府県地価調査の座標\n",
        "pref_xy = np.vstack([\n",
        "    pref_land_gdf.geometry.x.values,\n",
        "    pref_land_gdf.geometry.y.values\n",
        "]).T\n",
        "\n",
        "pref_tree = KDTree(pref_xy)\n",
        "pref_prices = pref_land_gdf[\"pref_land_price\"].values\n",
        "\n",
        "#最近傍価格を取得する関数\n",
        "def nearest_pref_land_price(pt, tree, prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return prices[idx[0][0]]\n",
        "\n",
        "#train / test に付与\n",
        "train_gdf[\"nearest_pref_land_price\"] = train_gdf[\"geometry\"].apply(\n",
        "    lambda pt: nearest_pref_land_price(pt, pref_tree, pref_prices)\n",
        ")\n",
        "\n",
        "test_gdf[\"nearest_pref_land_price\"] = test_gdf[\"geometry\"].apply(\n",
        "    lambda pt: nearest_pref_land_price(pt, pref_tree, pref_prices)\n",
        ")\n",
        "\n",
        "# DataFrame に戻す\n",
        "train[\"nearest_pref_land_price\"] = train_gdf[\"nearest_pref_land_price\"].values\n",
        "test[\"nearest_pref_land_price\"]  = test_gdf[\"nearest_pref_land_price\"].values\n",
        "\n",
        "#欠損処理 + log 特徴量\n",
        "for df in [train, test]:\n",
        "    df[\"nearest_pref_land_price\"] = df[\"nearest_pref_land_price\"].fillna(0)\n",
        "    df[\"nearest_pref_land_price_log\"] = np.log1p(df[\"nearest_pref_land_price\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "Tc8IByo9JaMY"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# DID データ読み込み\n",
        "# =========================\n",
        "did_gdf = gpd.read_file(\"/content/A16-20_00_DID.shp\")\n",
        "\n",
        "# 人口・面積カラム\n",
        "DID_POP_COL  = \"A16_005\"\n",
        "DID_AREA_COL = \"A16_006\"\n",
        "\n",
        "# 密度\n",
        "did_gdf[\"DID_density\"] = did_gdf[DID_POP_COL] / (did_gdf[DID_AREA_COL] + 1e-6)\n",
        "\n",
        "# CRS統一\n",
        "did_gdf = did_gdf.to_crs(epsg=3857)\n",
        "\n",
        "#train / test を GeoDataFrame に変換\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=gpd.points_from_xy(train[\"lon\"], train[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=gpd.points_from_xy(test[\"lon\"], test[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "#KDTree用の座標準備\n",
        "# DIDポリゴンの代表点（centroid）\n",
        "did_coords = np.vstack([\n",
        "    did_gdf.geometry.centroid.x,\n",
        "    did_gdf.geometry.centroid.y\n",
        "]).T\n",
        "\n",
        "tree = KDTree(did_coords)\n",
        "\n",
        "#最近傍DIDを割り当てる関数\n",
        "def attach_DID_features(base_gdf, did_gdf, tree):\n",
        "    coords = np.vstack([\n",
        "        base_gdf.geometry.x,\n",
        "        base_gdf.geometry.y\n",
        "    ]).T\n",
        "\n",
        "    _, idx = tree.query(coords, k=1)\n",
        "\n",
        "    base_gdf[\"DID_population\"] = did_gdf.iloc[idx.flatten()][DID_POP_COL].values\n",
        "    base_gdf[\"DID_area\"]       = did_gdf.iloc[idx.flatten()][DID_AREA_COL].values\n",
        "    base_gdf[\"DID_density\"]    = did_gdf.iloc[idx.flatten()][\"DID_density\"].values\n",
        "\n",
        "    return base_gdf\n",
        "\n",
        "#train / test にDID付与\n",
        "train_gdf = attach_DID_features(train_gdf, did_gdf, tree)\n",
        "test_gdf  = attach_DID_features(test_gdf,  did_gdf, tree)\n",
        "\n",
        "#geometryを落として DataFrame に戻す\n",
        "train = pd.DataFrame(train_gdf.drop(columns=\"geometry\"))\n",
        "test  = pd.DataFrame(test_gdf.drop(columns=\"geometry\"))\n",
        "\n",
        "#欠損処理\n",
        "for col in [\"DID_population\", \"DID_area\", \"DID_density\"]:\n",
        "    train[col] = train[col].fillna(0)\n",
        "    test[col]  = test[col].fillna(0)\n",
        "\n",
        "    train[f\"{col}_log\"] = np.log1p(train[col])\n",
        "    test[f\"{col}_log\"]  = np.log1p(test[col])"
      ],
      "metadata": {
        "id": "5GX6zgeQqr9W"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 駅乗降客数（2019年）\n",
        "# =========================\n",
        "df = pd.read_csv(\"S12-24_NumberOfPassengers_utf8.csv\")\n",
        "df_2019 = df[(df[\"S12_039\"]==1)&(df[\"S12_038\"]==1)]\n",
        "station_2019 = df_2019.groupby(\"S12_001c\", as_index=False).agg(passengers_2019=(\"S12_041\",\"sum\")).rename(columns={\"S12_001c\":\"station_code\"})\n"
      ],
      "metadata": {
        "id": "lSMvSRsVqs4T"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 3. 駅ポイント（lon / lat）\n",
        "# =========================\n",
        "station_point_gdf = gpd.read_file(\"/content/S12-24_NumberOfPassengers.geojson\")\n",
        "station_point_gdf[\"S12_001c\"] = station_point_gdf[\"S12_001c\"].astype(str)\n",
        "station_2019[\"station_code\"] = station_2019[\"station_code\"].astype(str)\n",
        "stations = station_point_gdf.merge(station_2019, left_on=\"S12_001c\", right_on=\"station_code\", how=\"left\")\n",
        "stations = stations.to_crs(epsg=3857)\n",
        "stations[\"geometry\"] = stations.geometry.centroid\n",
        "stations_gdf = stations[[\"S12_001c\",\"passengers_2019\",\"geometry\"]].copy()\n",
        "stations_gdf.crs = \"EPSG:3857\""
      ],
      "metadata": {
        "id": "pRiaY6GRqw4O"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 駅特徴量作成関数\n",
        "# =========================\n",
        "def add_station_features(df, stations_gdf, radius=500):\n",
        "    df = df.copy()\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
        "\n",
        "    # 既存の index_right を削除\n",
        "    if \"index_right\" in gdf.columns:\n",
        "        gdf = gdf.drop(columns=[\"index_right\"])\n",
        "    if \"index_right\" in stations_gdf.columns:\n",
        "        stations_gdf = stations_gdf.drop(columns=[\"index_right\"])\n",
        "\n",
        "    joined = gpd.sjoin(gdf, stations_gdf, how=\"left\", predicate=\"dwithin\", distance=radius)\n",
        "\n",
        "    feat = joined.groupby(\"building_id\", as_index=False).agg(\n",
        "        **{\n",
        "            f\"station_passengers_{radius}m_sum\": (\"passengers_2019\",\"sum\"),\n",
        "            f\"station_passengers_{radius}m_max\": (\"passengers_2019\",\"max\"),\n",
        "            f\"station_passengers_{radius}m_mean\": (\"passengers_2019\",\"mean\")\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df = df.merge(feat, on=\"building_id\", how=\"left\")\n",
        "    for col in feat.columns:\n",
        "        if col != \"building_id\":\n",
        "            df[col] = df[col].fillna(0)\n",
        "            df[col + \"_log\"] = np.log1p(df[col])\n",
        "    return df"
      ],
      "metadata": {
        "id": "sUXL1k5Iqz2W"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 5. train/testに駅特徴量付与\n",
        "# =========================\n",
        "for radius in [500,1000]:\n",
        "    train = add_station_features(train, stations_gdf, radius)\n",
        "    test  = add_station_features(test, stations_gdf, radius)"
      ],
      "metadata": {
        "id": "OQWjRqnZq3mu"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4. 築年 → age（target_ymからyear_built）\n",
        "# year_builtはYYYYMM形式\n",
        "# =========================================================\n",
        "for df in [train,test]:\n",
        "    df[\"sale_year\"] = df[\"target_ym\"] // 100\n",
        "    df[\"age\"] = (df[\"sale_year\"] - (df[\"year_built\"] // 100)).clip(0,100)"
      ],
      "metadata": {
        "id": "YldeUXEiq5nO"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. 地価公示データ\n",
        "# =========================\n",
        "land_gdf = gpd.read_file(\"/content/L01-23.geojson\").to_crs(epsg=4326)\n",
        "for df in [train,test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "train_gdf = gpd.GeoDataFrame(train, geometry=\"geometry\", crs=\"EPSG:4326\").to_crs(epsg=6668)\n",
        "test_gdf  = gpd.GeoDataFrame(test,  geometry=\"geometry\", crs=\"EPSG:4326\").to_crs(epsg=6668)\n",
        "\n",
        "land_gdf  = land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "land_xy = np.vstack([land_gdf.geometry.x.values, land_gdf.geometry.y.values]).T\n",
        "tree = KDTree(land_xy)\n",
        "land_prices = land_gdf['L01_006'].values\n",
        "\n",
        "def nearest_land_price_fast(pt, tree, land_prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return land_prices[idx[0][0]]\n",
        "\n",
        "train_gdf['nearest_land_price'] = train_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "test_gdf['nearest_land_price']  = test_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "train['final_land_price'] = train_gdf['nearest_land_price'].values\n",
        "test['final_land_price']  = test_gdf['nearest_land_price'].values"
      ],
      "metadata": {
        "id": "7re7RBC_q7ZC"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 6. 時期特徴量（年×マンション、年×首都圏、年×DID）\n",
        "# =========================================================\n",
        "CAPITAL_PREF_CODES = [13,14,12,11]  # 東京・神奈川・千葉・埼玉\n",
        "for df in [train,test]:\n",
        "    # base年は任意、ageに依存させるので安全\n",
        "    df[\"is_mansion\"] = (df[\"building_type\"] == 1).astype(int)\n",
        "    df[\"is_capital\"] = df[\"addr1_1\"].isin(CAPITAL_PREF_CODES).astype(int)\n",
        "    df[\"is_DID\"] = (df[\"DID_population\"] > 0).astype(int)\n",
        "\n",
        "    # 年×特徴量は age を使う\n",
        "    df[\"year_x_mansion\"] = df[\"age\"] * df[\"is_mansion\"]\n",
        "    df[\"year_x_capital\"] = df[\"age\"] * df[\"is_capital\"]\n",
        "    df[\"year_x_DID\"] = df[\"age\"] * df[\"is_DID\"]"
      ],
      "metadata": {
        "id": "sYz5h0qpJPri"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. マンション/戸建てに分割\n",
        "# =========================\n",
        "train_mansion = train[train['building_type'] == 1].copy()\n",
        "train_house   = train[train['building_type'] == 4].copy()\n",
        "test_mansion  = test[test['building_type'] == 1].copy()\n",
        "test_house    = test[test['building_type'] == 4].copy()"
      ],
      "metadata": {
        "id": "QR2D8BTps1eT"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 8. 特徴量リスト\n",
        "# =========================================================\n",
        "common_features = [\n",
        "    'target_ym','lon','lat',\n",
        "    'drugstore_distance','bank_distance','shopping_street_distance',\n",
        "    'parking_keiyaku','money_hoshou_company','free_rent_duration','free_rent_gen_timing',\n",
        "    'addr1','addr2','addr3','post1','post2',\"nearest_pref_land_price\",\n",
        "    \"nearest_pref_land_price_log\"\n",
        "]\n",
        "common_features += [\"year_x_capital\",\"year_x_DID\",\"age\"]\n",
        "\n",
        "mansion_features = common_features + [\n",
        "    'house_area','floor','room_count','total_units','building_structure','has_elevator','has_gym','maintenance_fee',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean',\n",
        "    'year_x_mansion'\n",
        "]\n",
        "\n",
        "house_features = common_features + [\n",
        "    'house_area','land_area','floor_count','room_count','building_structure',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean'\n",
        "]\n"
      ],
      "metadata": {
        "id": "XSH3UlBQs63P"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 学習用データ作成関数\n",
        "# =========================\n",
        "\n",
        "DROP_COLS = [\n",
        "    \"building_id\",\n",
        "    \"money_room\",\n",
        "    \"money_hoshou_company\"\n",
        "]\n",
        "\n",
        "def make_features(df):\n",
        "    return [\n",
        "        c for c in df.columns\n",
        "        if c not in DROP_COLS\n",
        "        and df[c].dtype != \"object\"\n",
        "    ]\n",
        "\n",
        "mansion_features = make_features(train_mansion)\n",
        "house_features   = make_features(train_house)\n",
        "\n",
        "def prepare_Xy(df, features, is_train=True):\n",
        "    X = df[[c for c in features if c in df.columns]].copy()\n",
        "\n",
        "    # geometry が紛れ込んでも必ず落とす\n",
        "    if \"geometry\" in X.columns:\n",
        "        X = X.drop(columns=[\"geometry\"])\n",
        "\n",
        "    # 数値型だけに限定（最終防衛ライン）\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "    if is_train:\n",
        "        y = np.log1p(df[\"money_room\"])\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "X_mansion, y_mansion = prepare_Xy(train_mansion, mansion_features)\n",
        "X_house, y_house     = prepare_Xy(train_house, house_features)\n",
        "\n",
        "X_test_mansion = test_mansion[mansion_features].copy()\n",
        "X_test_house   = test_house[house_features].copy()\n"
      ],
      "metadata": {
        "id": "7Comaq9hqQ0U"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ##テスト！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
        "# fair_c_values = [0.05, 0.08, 0.1, 0.12, 0.15, 0.2]\n",
        "\n",
        "# def evaluate_fair_c_split(X, y, category_name='Mansion'):\n",
        "#     from sklearn.model_selection import train_test_split\n",
        "\n",
        "#     # train/valid分割\n",
        "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#     results = []\n",
        "#     for fair_c in fair_c_values:\n",
        "#         params = {\n",
        "#             'objective': 'fair',\n",
        "#             'metric': 'rmse',\n",
        "#             'boosting_type': 'gbdt',\n",
        "#             'num_leaves': 31,\n",
        "#             'fair_c': fair_c,\n",
        "#             'verbose': -1,\n",
        "#             'random_state': 42\n",
        "#         }\n",
        "\n",
        "#         train_data = lgb.Dataset(X_train, label=y_train)\n",
        "#         valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "\n",
        "#         model = lgb.train(\n",
        "#             params,\n",
        "#             train_data,\n",
        "#             num_boost_round=3000,\n",
        "#             valid_sets=[valid_data],\n",
        "#             early_stopping_rounds=200,\n",
        "#             verbose_eval=False\n",
        "#         )\n",
        "\n",
        "#         y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "#         mape = np.mean(np.abs((y_val - y_pred) / y_val))\n",
        "#         results.append((fair_c, mape))\n",
        "#         print(f\"{category_name} - fair_c: {fair_c:.2f}, MAPE: {mape:.6f}\")\n",
        "\n",
        "#     # 最良値\n",
        "#     best_fair_c, best_mape = min(results, key=lambda x: x[1])\n",
        "#     print(f\"==> {category_name} 最適 fair_c: {best_fair_c}, MAPE: {best_mape:.6f}\\n\")\n",
        "#     return results, (best_fair_c, best_mape)\n",
        "\n",
        "# # =========================================================\n",
        "# # マンション・戸建で評価\n",
        "# # =========================================================\n",
        "# print(\"マンション fair_c スキャン\")\n",
        "# mansion_results, mansion_best = evaluate_fair_c_split(X_mansion, y_mansion, 'マンション')\n",
        "\n",
        "# print(\"戸建 fair_c スキャン\")\n",
        "# house_results, house_best = evaluate_fair_c_split(X_house, y_house, '戸建')\n",
        "\n"
      ],
      "metadata": {
        "id": "ExJLI2KBSUX6"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 学習関数\n",
        "# =========================\n",
        "def train_lgb(X, y, seed):\n",
        "    model = lgb.LGBMRegressor(\n",
        "        n_estimators=100000,\n",
        "        learning_rate=0.1,\n",
        "        num_leaves=64,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        objective=\"regression\",\n",
        "        metric=\"l1\",\n",
        "        min_child_samples=20,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.2,\n",
        "        random_state=seed     # ★ split も seed 揃える\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_metric=\"l1\",\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=200),\n",
        "            lgb.log_evaluation(200),\n",
        "        ],\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "RLzwmUKeqUy0"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. モデル学習\n",
        "# =========================\n",
        "models_mansion = []\n",
        "models_house   = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"Training seed={seed}\")\n",
        "    models_mansion.append(train_lgb(X_mansion, y_mansion, seed))\n",
        "    models_house.append(train_lgb(X_house, y_house, seed))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGud5_oyqXXP",
        "outputId": "421e21c1-beef-4afe-8b1b-cfc806bea90f"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training seed=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096159 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14772\n",
            "[LightGBM] [Info] Number of data points in the train set: 155660, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.925363\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's l1: 0.129805\n",
            "[400]\tvalid_0's l1: 0.122896\n",
            "[600]\tvalid_0's l1: 0.118901\n",
            "[800]\tvalid_0's l1: 0.116107\n",
            "[1000]\tvalid_0's l1: 0.114042\n",
            "[1200]\tvalid_0's l1: 0.112265\n",
            "[1400]\tvalid_0's l1: 0.110943\n",
            "[1600]\tvalid_0's l1: 0.109787\n",
            "[1800]\tvalid_0's l1: 0.108846\n",
            "[2000]\tvalid_0's l1: 0.108051\n",
            "[2200]\tvalid_0's l1: 0.107427\n",
            "[2400]\tvalid_0's l1: 0.106763\n",
            "[2600]\tvalid_0's l1: 0.106262\n",
            "[2800]\tvalid_0's l1: 0.105816\n",
            "[3000]\tvalid_0's l1: 0.105473\n",
            "[3200]\tvalid_0's l1: 0.105136\n",
            "[3400]\tvalid_0's l1: 0.104858\n",
            "[3600]\tvalid_0's l1: 0.104574\n",
            "[3800]\tvalid_0's l1: 0.104356\n",
            "[4000]\tvalid_0's l1: 0.104152\n",
            "[4200]\tvalid_0's l1: 0.103956\n",
            "[4400]\tvalid_0's l1: 0.103797\n",
            "[4600]\tvalid_0's l1: 0.103617\n",
            "[4800]\tvalid_0's l1: 0.10347\n",
            "[5000]\tvalid_0's l1: 0.10335\n",
            "[5200]\tvalid_0's l1: 0.103222\n",
            "[5400]\tvalid_0's l1: 0.103114\n",
            "[5600]\tvalid_0's l1: 0.103013\n",
            "[5800]\tvalid_0's l1: 0.102938\n",
            "[6000]\tvalid_0's l1: 0.102837\n",
            "[6200]\tvalid_0's l1: 0.10277\n",
            "[6400]\tvalid_0's l1: 0.102688\n",
            "[6600]\tvalid_0's l1: 0.102635\n",
            "[6800]\tvalid_0's l1: 0.102564\n",
            "[7000]\tvalid_0's l1: 0.102501\n",
            "[7200]\tvalid_0's l1: 0.102445\n",
            "[7400]\tvalid_0's l1: 0.10239\n",
            "[7600]\tvalid_0's l1: 0.10234\n",
            "[7800]\tvalid_0's l1: 0.102306\n",
            "[8000]\tvalid_0's l1: 0.102266\n",
            "[8200]\tvalid_0's l1: 0.102215\n",
            "[8400]\tvalid_0's l1: 0.102174\n",
            "[8600]\tvalid_0's l1: 0.102148\n",
            "[8800]\tvalid_0's l1: 0.102111\n",
            "[9000]\tvalid_0's l1: 0.102078\n",
            "[9200]\tvalid_0's l1: 0.102053\n",
            "[9400]\tvalid_0's l1: 0.102029\n",
            "[9600]\tvalid_0's l1: 0.102004\n",
            "[9800]\tvalid_0's l1: 0.101982\n",
            "[10000]\tvalid_0's l1: 0.101956\n",
            "[10200]\tvalid_0's l1: 0.101931\n",
            "[10400]\tvalid_0's l1: 0.101913\n",
            "[10600]\tvalid_0's l1: 0.101894\n",
            "[10800]\tvalid_0's l1: 0.101874\n",
            "[11000]\tvalid_0's l1: 0.101856\n",
            "[11200]\tvalid_0's l1: 0.101843\n",
            "[11400]\tvalid_0's l1: 0.101826\n",
            "[11600]\tvalid_0's l1: 0.101814\n",
            "[11800]\tvalid_0's l1: 0.101802\n",
            "[12000]\tvalid_0's l1: 0.101787\n",
            "[12200]\tvalid_0's l1: 0.101774\n",
            "[12400]\tvalid_0's l1: 0.101765\n",
            "[12600]\tvalid_0's l1: 0.101752\n",
            "[12800]\tvalid_0's l1: 0.10174\n",
            "[13000]\tvalid_0's l1: 0.101728\n",
            "[13200]\tvalid_0's l1: 0.101725\n",
            "[13400]\tvalid_0's l1: 0.101716\n",
            "[13600]\tvalid_0's l1: 0.101707\n",
            "[13800]\tvalid_0's l1: 0.101696\n",
            "[14000]\tvalid_0's l1: 0.10169\n",
            "[14200]\tvalid_0's l1: 0.101683\n",
            "[14400]\tvalid_0's l1: 0.101678\n",
            "[14600]\tvalid_0's l1: 0.101673\n",
            "[14800]\tvalid_0's l1: 0.10167\n",
            "[15000]\tvalid_0's l1: 0.101665\n",
            "[15200]\tvalid_0's l1: 0.101662\n",
            "[15400]\tvalid_0's l1: 0.101653\n",
            "[15600]\tvalid_0's l1: 0.101649\n",
            "[15800]\tvalid_0's l1: 0.10164\n",
            "[16000]\tvalid_0's l1: 0.101634\n",
            "[16200]\tvalid_0's l1: 0.101629\n",
            "[16400]\tvalid_0's l1: 0.101625\n",
            "[16600]\tvalid_0's l1: 0.10162\n",
            "[16800]\tvalid_0's l1: 0.101612\n",
            "[17000]\tvalid_0's l1: 0.101608\n",
            "[17200]\tvalid_0's l1: 0.101605\n",
            "[17400]\tvalid_0's l1: 0.101598\n",
            "[17600]\tvalid_0's l1: 0.101594\n",
            "[17800]\tvalid_0's l1: 0.101589\n",
            "[18000]\tvalid_0's l1: 0.101584\n",
            "[18200]\tvalid_0's l1: 0.101584\n",
            "[18400]\tvalid_0's l1: 0.10158\n",
            "[18600]\tvalid_0's l1: 0.101577\n",
            "[18800]\tvalid_0's l1: 0.10157\n",
            "[19000]\tvalid_0's l1: 0.10157\n",
            "[19200]\tvalid_0's l1: 0.101567\n",
            "[19400]\tvalid_0's l1: 0.101562\n",
            "[19600]\tvalid_0's l1: 0.101557\n",
            "[19800]\tvalid_0's l1: 0.101554\n",
            "[20000]\tvalid_0's l1: 0.101554\n",
            "[20200]\tvalid_0's l1: 0.101552\n",
            "[20400]\tvalid_0's l1: 0.101547\n",
            "[20600]\tvalid_0's l1: 0.101545\n",
            "[20800]\tvalid_0's l1: 0.10154\n",
            "[21000]\tvalid_0's l1: 0.101535\n",
            "[21200]\tvalid_0's l1: 0.101532\n",
            "[21400]\tvalid_0's l1: 0.10153\n",
            "[21600]\tvalid_0's l1: 0.101529\n",
            "[21800]\tvalid_0's l1: 0.101524\n",
            "[22000]\tvalid_0's l1: 0.101523\n",
            "[22200]\tvalid_0's l1: 0.101521\n",
            "[22400]\tvalid_0's l1: 0.101517\n",
            "[22600]\tvalid_0's l1: 0.101515\n",
            "[22800]\tvalid_0's l1: 0.101514\n",
            "[23000]\tvalid_0's l1: 0.101514\n",
            "Early stopping, best iteration is:\n",
            "[22808]\tvalid_0's l1: 0.101513\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094860 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12777\n",
            "[LightGBM] [Info] Number of data points in the train set: 121743, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.799404\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's l1: 0.178006\n",
            "[400]\tvalid_0's l1: 0.168282\n",
            "[600]\tvalid_0's l1: 0.162388\n",
            "[800]\tvalid_0's l1: 0.157813\n",
            "[1000]\tvalid_0's l1: 0.154425\n",
            "[1200]\tvalid_0's l1: 0.151571\n",
            "[1400]\tvalid_0's l1: 0.149251\n",
            "[1600]\tvalid_0's l1: 0.147322\n",
            "[1800]\tvalid_0's l1: 0.14556\n",
            "[2000]\tvalid_0's l1: 0.144039\n",
            "[2200]\tvalid_0's l1: 0.142826\n",
            "[2400]\tvalid_0's l1: 0.14165\n",
            "[2600]\tvalid_0's l1: 0.140589\n",
            "[2800]\tvalid_0's l1: 0.139875\n",
            "[3000]\tvalid_0's l1: 0.139151\n",
            "[3200]\tvalid_0's l1: 0.138489\n",
            "[3400]\tvalid_0's l1: 0.137928\n",
            "[3600]\tvalid_0's l1: 0.137438\n",
            "[3800]\tvalid_0's l1: 0.136916\n",
            "[4000]\tvalid_0's l1: 0.136488\n",
            "[4200]\tvalid_0's l1: 0.1361\n",
            "[4400]\tvalid_0's l1: 0.135766\n",
            "[4600]\tvalid_0's l1: 0.135438\n",
            "[4800]\tvalid_0's l1: 0.135124\n",
            "[5000]\tvalid_0's l1: 0.134884\n",
            "[5200]\tvalid_0's l1: 0.134657\n",
            "[5400]\tvalid_0's l1: 0.134448\n",
            "[5600]\tvalid_0's l1: 0.134262\n",
            "[5800]\tvalid_0's l1: 0.134081\n",
            "[6000]\tvalid_0's l1: 0.13389\n",
            "[6200]\tvalid_0's l1: 0.133729\n",
            "[6400]\tvalid_0's l1: 0.13355\n",
            "[6600]\tvalid_0's l1: 0.133406\n",
            "[6800]\tvalid_0's l1: 0.133264\n",
            "[7000]\tvalid_0's l1: 0.133147\n",
            "[7200]\tvalid_0's l1: 0.133025\n",
            "[7400]\tvalid_0's l1: 0.132912\n",
            "[7600]\tvalid_0's l1: 0.132824\n",
            "[7800]\tvalid_0's l1: 0.132731\n",
            "[8000]\tvalid_0's l1: 0.132653\n",
            "[8200]\tvalid_0's l1: 0.13257\n",
            "[8400]\tvalid_0's l1: 0.132495\n",
            "[8600]\tvalid_0's l1: 0.132429\n",
            "[8800]\tvalid_0's l1: 0.132374\n",
            "[9000]\tvalid_0's l1: 0.132316\n",
            "[9200]\tvalid_0's l1: 0.132273\n",
            "[9400]\tvalid_0's l1: 0.132235\n",
            "[9600]\tvalid_0's l1: 0.132191\n",
            "[9800]\tvalid_0's l1: 0.132143\n",
            "[10000]\tvalid_0's l1: 0.13211\n",
            "[10200]\tvalid_0's l1: 0.132064\n",
            "[10400]\tvalid_0's l1: 0.132028\n",
            "[10600]\tvalid_0's l1: 0.131992\n",
            "[10800]\tvalid_0's l1: 0.131966\n",
            "[11000]\tvalid_0's l1: 0.13192\n",
            "[11200]\tvalid_0's l1: 0.131889\n",
            "[11400]\tvalid_0's l1: 0.131848\n",
            "[11600]\tvalid_0's l1: 0.131826\n",
            "[11800]\tvalid_0's l1: 0.131796\n",
            "[12000]\tvalid_0's l1: 0.131772\n",
            "[12200]\tvalid_0's l1: 0.131756\n",
            "[12400]\tvalid_0's l1: 0.131732\n",
            "[12600]\tvalid_0's l1: 0.131707\n",
            "[12800]\tvalid_0's l1: 0.131691\n",
            "[13000]\tvalid_0's l1: 0.131675\n",
            "[13200]\tvalid_0's l1: 0.131655\n",
            "[13400]\tvalid_0's l1: 0.131635\n",
            "[13600]\tvalid_0's l1: 0.131629\n",
            "[13800]\tvalid_0's l1: 0.131613\n",
            "[14000]\tvalid_0's l1: 0.131604\n",
            "[14200]\tvalid_0's l1: 0.13159\n",
            "[14400]\tvalid_0's l1: 0.131577\n",
            "[14600]\tvalid_0's l1: 0.131571\n",
            "[14800]\tvalid_0's l1: 0.131567\n",
            "[15000]\tvalid_0's l1: 0.131556\n",
            "[15200]\tvalid_0's l1: 0.131543\n",
            "[15400]\tvalid_0's l1: 0.131536\n",
            "[15600]\tvalid_0's l1: 0.131529\n",
            "[15800]\tvalid_0's l1: 0.131522\n",
            "[16000]\tvalid_0's l1: 0.131512\n",
            "[16200]\tvalid_0's l1: 0.131507\n",
            "[16400]\tvalid_0's l1: 0.131502\n",
            "[16600]\tvalid_0's l1: 0.13149\n",
            "[16800]\tvalid_0's l1: 0.131487\n",
            "[17000]\tvalid_0's l1: 0.131481\n",
            "[17200]\tvalid_0's l1: 0.131474\n",
            "[17400]\tvalid_0's l1: 0.131466\n",
            "[17600]\tvalid_0's l1: 0.131461\n",
            "[17800]\tvalid_0's l1: 0.131456\n",
            "[18000]\tvalid_0's l1: 0.13145\n",
            "[18200]\tvalid_0's l1: 0.131444\n",
            "[18400]\tvalid_0's l1: 0.131439\n",
            "[18600]\tvalid_0's l1: 0.131435\n",
            "[18800]\tvalid_0's l1: 0.131431\n",
            "[19000]\tvalid_0's l1: 0.131428\n",
            "[19200]\tvalid_0's l1: 0.131423\n",
            "[19400]\tvalid_0's l1: 0.131419\n",
            "[19600]\tvalid_0's l1: 0.131418\n",
            "[19800]\tvalid_0's l1: 0.131413\n",
            "[20000]\tvalid_0's l1: 0.13141\n",
            "[20200]\tvalid_0's l1: 0.131407\n",
            "[20400]\tvalid_0's l1: 0.131407\n",
            "[20600]\tvalid_0's l1: 0.131402\n",
            "[20800]\tvalid_0's l1: 0.131398\n",
            "[21000]\tvalid_0's l1: 0.131393\n",
            "[21200]\tvalid_0's l1: 0.131391\n",
            "[21400]\tvalid_0's l1: 0.131388\n",
            "[21600]\tvalid_0's l1: 0.131385\n",
            "[21800]\tvalid_0's l1: 0.131384\n",
            "[22000]\tvalid_0's l1: 0.13138\n",
            "[22200]\tvalid_0's l1: 0.131379\n",
            "[22400]\tvalid_0's l1: 0.131378\n",
            "[22600]\tvalid_0's l1: 0.131375\n",
            "[22800]\tvalid_0's l1: 0.131374\n",
            "[23000]\tvalid_0's l1: 0.131373\n",
            "[23200]\tvalid_0's l1: 0.13137\n",
            "[23400]\tvalid_0's l1: 0.131367\n",
            "[23600]\tvalid_0's l1: 0.131362\n",
            "[23800]\tvalid_0's l1: 0.13136\n",
            "[24000]\tvalid_0's l1: 0.131357\n",
            "[24200]\tvalid_0's l1: 0.131357\n",
            "Early stopping, best iteration is:\n",
            "[24008]\tvalid_0's l1: 0.131357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. 学習時の列を保存\n",
        "# =========================\n",
        "cols_mansion = X_mansion.columns.tolist()\n",
        "cols_house   = X_house.columns.tolist()\n",
        "\n",
        "# =========================\n",
        "# アンサンブル予測関数\n",
        "# =========================\n",
        "def ensemble_predict(models, X):\n",
        "    preds = []\n",
        "    for model in models:\n",
        "        preds.append(model.predict(X))\n",
        "    return np.mean(preds, axis=0)\n"
      ],
      "metadata": {
        "id": "g_ByR_IU8bly"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# test を building_type で3分割\n",
        "# =========================\n",
        "test_mansion = test[test[\"building_type\"] == 1].copy()\n",
        "test_house   = test[test[\"building_type\"] == 4].copy()\n",
        "test_other   = test[\n",
        "    ~test.index.isin(test_mansion.index) &\n",
        "    ~test.index.isin(test_house.index)\n",
        "].copy()"
      ],
      "metadata": {
        "id": "uDUK-gZf8e9W"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# test の特徴量を「学習時列」と完全一致\n",
        "# =========================\n",
        "X_test_mansion = test_mansion.reindex(\n",
        "    columns=cols_mansion,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "X_test_house = test_house.reindex(\n",
        "    columns=cols_house,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "X_test_other = test_other.reindex(\n",
        "    columns=cols_mansion,\n",
        "    fill_value=0\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "81tyKwPSqZjT"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##テスト！最適なスケール値を探す。全部コメント化\n",
        "\n",
        "# import numpy as np\n",
        "# from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "# # =========================\n",
        "# # 1. 予測値（補正前）を作成\n",
        "# # =========================\n",
        "# y_pred_mansion_raw = np.expm1(model_mansion.predict(X_mansion))\n",
        "# y_pred_house_raw   = np.expm1(model_house.predict(X_house))\n",
        "\n",
        "# y_true_mansion = np.expm1(y_mansion)\n",
        "# y_true_house   = np.expm1(y_house)\n",
        "\n",
        "# LOW_TH_MANSION = 9_000_000\n",
        "# LOW_TH_HOUSE   = 9_000_000\n",
        "\n",
        "# # =========================\n",
        "# # 2. 0.70 ~ 1.00 の範囲でスケールをテスト\n",
        "# # =========================\n",
        "# scales = np.arange(0.70, 1.01, 0.01)  # 0.01刻みで細かく探索\n",
        "\n",
        "# results_mansion = []\n",
        "# results_house   = []\n",
        "\n",
        "# for scale in scales:\n",
        "#     # --- マンション ---\n",
        "#     y_pred = y_pred_mansion_raw.copy()\n",
        "#     mask_low = y_pred <= LOW_TH_MANSION\n",
        "#     y_pred[mask_low] *= scale\n",
        "#     mape = mean_absolute_percentage_error(y_true_mansion, y_pred)\n",
        "#     results_mansion.append((scale, mape))\n",
        "\n",
        "#     # --- 戸建 ---\n",
        "#     y_pred = y_pred_house_raw.copy()\n",
        "#     mask_low = y_pred <= LOW_TH_HOUSE\n",
        "#     y_pred[mask_low] *= scale\n",
        "#     mape = mean_absolute_percentage_error(y_true_house, y_pred)\n",
        "#     results_house.append((scale, mape))\n",
        "\n",
        "# # =========================\n",
        "# # 3. 結果を確認\n",
        "# # =========================\n",
        "# results_mansion = sorted(results_mansion, key=lambda x: x[1])\n",
        "# results_house   = sorted(results_house, key=lambda x: x[1])\n",
        "\n",
        "# print(\"マンション: 最適スケールとMAPE上位5\")\n",
        "# for s, m in results_mansion[:5]:\n",
        "#     print(f\"scale={s:.2f}, MAPE={m:.6f}\")\n",
        "\n",
        "# print(\"\\n戸建: 最適スケールとMAPE上位5\")\n",
        "# for s, m in results_house[:5]:\n",
        "#     print(f\"scale={s:.2f}, MAPE={m:.6f}\")\n"
      ],
      "metadata": {
        "id": "HWvh7Rp0_u8g"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 低価格帯補正つき予測\n",
        "# =========================\n",
        "LOW_TH_MANSION = 9_000_000\n",
        "LOW_TH_HOUSE   = 9_000_000\n",
        "\n",
        "LOW_SCALE_MANSION = 0.98\n",
        "LOW_SCALE_HOUSE   = 0.98\n",
        "\n",
        "\n",
        "def predict_with_low_scale(model, X, low_th, low_scale):\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # まず予測値側をガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=20,   # log空間での上限\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # log → 元スケール\n",
        "    y_pred = np.expm1(y_pred)\n",
        "\n",
        "    # 再度ガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=1e9,\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # 下限クリップ\n",
        "    y_pred = np.clip(y_pred, 1, 1e9)\n",
        "\n",
        "    # 低価格帯補正\n",
        "    mask_low = y_pred <= low_th\n",
        "    y_pred[mask_low] *= low_scale\n",
        "\n",
        "    return y_pred\n",
        "#マンション\n",
        "y_pred_test_mansion_log = ensemble_predict(\n",
        "    models_mansion,\n",
        "    X_test_mansion\n",
        ")\n",
        "\n",
        "y_pred_test_mansion = np.expm1(y_pred_test_mansion_log)\n",
        "\n",
        "mask_low = y_pred_test_mansion <= LOW_TH_MANSION\n",
        "y_pred_test_mansion[mask_low] *= LOW_SCALE_MANSION\n",
        "\n",
        "#戸建て\n",
        "y_pred_test_house_log = ensemble_predict(\n",
        "    models_house,\n",
        "    X_test_house\n",
        ")\n",
        "\n",
        "y_pred_test_house = np.expm1(y_pred_test_house_log)\n",
        "\n",
        "mask_low = y_pred_test_house <= LOW_TH_HOUSE\n",
        "y_pred_test_house[mask_low] *= LOW_SCALE_HOUSE\n",
        "\n",
        "#other\n",
        "y_pred_test_other_log = ensemble_predict(\n",
        "    models_mansion,\n",
        "    X_test_other\n",
        ")\n",
        "\n",
        "y_pred_test_other = np.expm1(y_pred_test_other_log)\n",
        "\n",
        "mask_low = y_pred_test_other <= LOW_TH_MANSION\n",
        "y_pred_test_other[mask_low] *= LOW_SCALE_MANSION\n"
      ],
      "metadata": {
        "id": "aaM1NflE8neh"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. test DataFrame に書き戻す\n",
        "# =========================\n",
        "test.loc[test_mansion.index, \"money_room\"] = y_pred_test_mansion\n",
        "test.loc[test_house.index,   \"money_room\"] = y_pred_test_house\n",
        "test.loc[test_other.index,   \"money_room\"] = y_pred_test_other\n",
        "\n",
        "test[\"money_room\"] = test[\"money_room\"].fillna(\n",
        "    test[\"money_room\"].median()\n",
        ")"
      ],
      "metadata": {
        "id": "TlSHkQ1hqcIM"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. submit.csv 作成\n",
        "# =========================\n",
        "submit = test[[\"id\", \"money_room\"]].sort_values(\"id\")\n",
        "submit.to_csv(\"submit.csv\", index=False, header=False)\n",
        "\n",
        "# NaN 確認\n",
        "import pandas as pd\n",
        "pd.read_csv(\"submit.csv\").isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "h_hPUSZp3t27",
        "outputId": "5dec8d35-26fa-4b48-84e1-af6cb07ba09e"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                   0\n",
              "15836195.5783917    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15836195.5783917</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# submit作成前に重複チェック\n",
        "test[['id']].duplicated().sum()\n",
        "# 0 なら id の重複はない\n"
      ],
      "metadata": {
        "id": "kwdYYm0LNWCw",
        "outputId": "4234264c-8d2e-4f05-8adb-14da11d2156b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAqEH7KeY8wSKs2mSDzmHe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondonrocket/kokudo/blob/%EF%BC%91%EF%BC%97%EF%BC%8E%EF%BC%90%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89base/16_1_mash_m2_mobile2_hasegawa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7Wc9jfop15s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import lightgbm as lgb\n",
        "from shapely.geometry import Point\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. train/test 読み込み\n",
        "# =========================\n",
        "train = pd.read_csv(\"/content/train.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)\n",
        "test  = pd.read_csv(\"/content/test.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)"
      ],
      "metadata": {
        "id": "322pg9pCqBZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. floor_count の異常値削除\n",
        "# =========================\n",
        "# 日本で一番高いマンションは64階なので70階以上は明らかに異常\n",
        "train = train.loc[train['floor_count'] <= 70]"
      ],
      "metadata": {
        "id": "xAFNw8K3O3Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. グローバル設定\n",
        "# =========================\n",
        "SEEDS = [42, 100, 202, 777, 999]\n"
      ],
      "metadata": {
        "id": "1fz6nvePZZZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 人口メッシュ GeoJSON 読み込み\n",
        "# =========================\n",
        "mesh_files = glob(\n",
        "    \"/content/drive/MyDrive/1km_mesh_2024_GEOJSON/**/*.geojson\",\n",
        "    recursive=True\n",
        ")\n",
        "\n",
        "gdfs = []\n",
        "for f in mesh_files:\n",
        "    gdf = gpd.read_file(f)\n",
        "\n",
        "    if gdf.crs is None:\n",
        "        gdf = gdf.set_crs(\"EPSG:4326\")\n",
        "    else:\n",
        "        gdf = gdf.to_crs(\"EPSG:4326\")\n",
        "\n",
        "    gdfs.append(gdf)\n",
        "\n",
        "pop_mesh = gpd.GeoDataFrame(\n",
        "    pd.concat(gdfs, ignore_index=True),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "POP_COLS = [\n",
        "    \"PT02_2025\",\n",
        "    \"PT08_2025\",\n",
        "    \"PT10_2025\",\n",
        "]\n",
        "\n",
        "pop_mesh = pop_mesh[[\"geometry\"] + POP_COLS]\n",
        "pop_mesh = pop_mesh.drop_duplicates(subset=[\"geometry\"])\n",
        "\n",
        "def to_gdf(df):\n",
        "    return gpd.GeoDataFrame(\n",
        "        df.copy(),\n",
        "        geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "\n",
        "train_gdf = to_gdf(train)\n",
        "test_gdf  = to_gdf(test)\n",
        "\n",
        "train = gpd.sjoin(\n",
        "    train_gdf,\n",
        "    pop_mesh,\n",
        "    how=\"left\",\n",
        "    predicate=\"within\"\n",
        ").drop(columns=[\"geometry\", \"index_right\"])\n",
        "\n",
        "test = gpd.sjoin(\n",
        "    test_gdf,\n",
        "    pop_mesh,\n",
        "    how=\"left\",\n",
        "    predicate=\"within\"\n",
        ").drop(columns=[\"geometry\", \"index_right\"])\n",
        "\n",
        "for c in POP_COLS:\n",
        "    train[c] = train[c].fillna(0)\n",
        "    test[c]  = test[c].fillna(0)\n",
        "\n",
        "assert len(train) == len(train_gdf)\n",
        "assert len(test)  == len(test_gdf)\n"
      ],
      "metadata": {
        "id": "kJE0eIo2_i0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 都道府県地価調査（2023）\n",
        "# =========================\n",
        "pref_land_gdf = gpd.read_file(\"/content/L02-23.geojson\")\n",
        "\n",
        "# 念のため CRS 統一（地価公示と同じ）\n",
        "pref_land_gdf = pref_land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "# 調査価格\n",
        "PRICE_COL = \"L02_006\"\n",
        "\n",
        "pref_land_gdf = pref_land_gdf[\n",
        "    [\"geometry\", PRICE_COL]\n",
        "].rename(columns={\n",
        "    PRICE_COL: \"pref_land_price\"\n",
        "})\n",
        "\n",
        "#train / test を GeoDataFrame に変換\n",
        "for df in [train, test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=\"geometry\",\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=6668)\n",
        "\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=\"geometry\",\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=6668)\n",
        "\n",
        "# 都道府県地価調査の座標\n",
        "pref_xy = np.vstack([\n",
        "    pref_land_gdf.geometry.x.values,\n",
        "    pref_land_gdf.geometry.y.values\n",
        "]).T\n",
        "\n",
        "pref_tree = KDTree(pref_xy)\n",
        "pref_prices = pref_land_gdf[\"pref_land_price\"].values\n",
        "\n",
        "#最近傍価格を取得する関数\n",
        "def nearest_pref_land_price(pt, tree, prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return prices[idx[0][0]]\n",
        "\n",
        "#train / test に付与\n",
        "train_gdf[\"nearest_pref_land_price\"] = train_gdf[\"geometry\"].apply(\n",
        "    lambda pt: nearest_pref_land_price(pt, pref_tree, pref_prices)\n",
        ")\n",
        "\n",
        "test_gdf[\"nearest_pref_land_price\"] = test_gdf[\"geometry\"].apply(\n",
        "    lambda pt: nearest_pref_land_price(pt, pref_tree, pref_prices)\n",
        ")\n",
        "\n",
        "# DataFrame に戻す\n",
        "train[\"nearest_pref_land_price\"] = train_gdf[\"nearest_pref_land_price\"].values\n",
        "test[\"nearest_pref_land_price\"]  = test_gdf[\"nearest_pref_land_price\"].values\n",
        "\n",
        "#欠損処理 + log 特徴量\n",
        "for df in [train, test]:\n",
        "    df[\"nearest_pref_land_price\"] = df[\"nearest_pref_land_price\"].fillna(0)\n",
        "    df[\"nearest_pref_land_price_log\"] = np.log1p(df[\"nearest_pref_land_price\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "Tc8IByo9JaMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# DID データ読み込み\n",
        "# =========================\n",
        "did_gdf = gpd.read_file(\"/content/A16-20_00_DID.shp\")\n",
        "\n",
        "# 人口・面積カラム\n",
        "DID_POP_COL  = \"A16_005\"\n",
        "DID_AREA_COL = \"A16_006\"\n",
        "\n",
        "# 密度\n",
        "did_gdf[\"DID_density\"] = did_gdf[DID_POP_COL] / (did_gdf[DID_AREA_COL] + 1e-6)\n",
        "\n",
        "# CRS統一\n",
        "did_gdf = did_gdf.to_crs(epsg=3857)\n",
        "\n",
        "#train / test を GeoDataFrame に変換\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=gpd.points_from_xy(train[\"lon\"], train[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=gpd.points_from_xy(test[\"lon\"], test[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "#KDTree用の座標準備\n",
        "# DIDポリゴンの代表点（centroid）\n",
        "did_coords = np.vstack([\n",
        "    did_gdf.geometry.centroid.x,\n",
        "    did_gdf.geometry.centroid.y\n",
        "]).T\n",
        "\n",
        "tree = KDTree(did_coords)\n",
        "\n",
        "#最近傍DIDを割り当てる関数\n",
        "def attach_DID_features(base_gdf, did_gdf, tree):\n",
        "    coords = np.vstack([\n",
        "        base_gdf.geometry.x,\n",
        "        base_gdf.geometry.y\n",
        "    ]).T\n",
        "\n",
        "    _, idx = tree.query(coords, k=1)\n",
        "\n",
        "    base_gdf[\"DID_population\"] = did_gdf.iloc[idx.flatten()][DID_POP_COL].values\n",
        "    base_gdf[\"DID_area\"]       = did_gdf.iloc[idx.flatten()][DID_AREA_COL].values\n",
        "    base_gdf[\"DID_density\"]    = did_gdf.iloc[idx.flatten()][\"DID_density\"].values\n",
        "\n",
        "    return base_gdf\n",
        "\n",
        "#train / test にDID付与\n",
        "train_gdf = attach_DID_features(train_gdf, did_gdf, tree)\n",
        "test_gdf  = attach_DID_features(test_gdf,  did_gdf, tree)\n",
        "\n",
        "#geometryを落として DataFrame に戻す\n",
        "train = pd.DataFrame(train_gdf.drop(columns=\"geometry\"))\n",
        "test  = pd.DataFrame(test_gdf.drop(columns=\"geometry\"))\n",
        "\n",
        "#欠損処理\n",
        "for col in [\"DID_population\", \"DID_area\", \"DID_density\"]:\n",
        "    train[col] = train[col].fillna(0)\n",
        "    test[col]  = test[col].fillna(0)\n",
        "\n",
        "    train[f\"{col}_log\"] = np.log1p(train[col])\n",
        "    test[f\"{col}_log\"]  = np.log1p(test[col])"
      ],
      "metadata": {
        "id": "5GX6zgeQqr9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 駅乗降客数（2019年）\n",
        "# =========================\n",
        "df = pd.read_csv(\"S12-24_NumberOfPassengers_utf8.csv\")\n",
        "df_2019 = df[(df[\"S12_039\"]==1)&(df[\"S12_038\"]==1)]\n",
        "station_2019 = df_2019.groupby(\"S12_001c\", as_index=False).agg(passengers_2019=(\"S12_041\",\"sum\")).rename(columns={\"S12_001c\":\"station_code\"})\n"
      ],
      "metadata": {
        "id": "lSMvSRsVqs4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 3. 駅ポイント（lon / lat）\n",
        "# =========================\n",
        "station_point_gdf = gpd.read_file(\"/content/S12-24_NumberOfPassengers.geojson\")\n",
        "station_point_gdf[\"S12_001c\"] = station_point_gdf[\"S12_001c\"].astype(str)\n",
        "station_2019[\"station_code\"] = station_2019[\"station_code\"].astype(str)\n",
        "stations = station_point_gdf.merge(station_2019, left_on=\"S12_001c\", right_on=\"station_code\", how=\"left\")\n",
        "stations = stations.to_crs(epsg=3857)\n",
        "stations[\"geometry\"] = stations.geometry.centroid\n",
        "stations_gdf = stations[[\"S12_001c\",\"passengers_2019\",\"geometry\"]].copy()\n",
        "stations_gdf.crs = \"EPSG:3857\""
      ],
      "metadata": {
        "id": "pRiaY6GRqw4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 駅特徴量作成関数\n",
        "# =========================\n",
        "def add_station_features(df, stations_gdf, radius=500):\n",
        "    df = df.copy()\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
        "\n",
        "    # 既存の index_right を削除\n",
        "    if \"index_right\" in gdf.columns:\n",
        "        gdf = gdf.drop(columns=[\"index_right\"])\n",
        "    if \"index_right\" in stations_gdf.columns:\n",
        "        stations_gdf = stations_gdf.drop(columns=[\"index_right\"])\n",
        "\n",
        "    joined = gpd.sjoin(gdf, stations_gdf, how=\"left\", predicate=\"dwithin\", distance=radius)\n",
        "\n",
        "    feat = joined.groupby(\"building_id\", as_index=False).agg(\n",
        "        **{\n",
        "            f\"station_passengers_{radius}m_sum\": (\"passengers_2019\",\"sum\"),\n",
        "            f\"station_passengers_{radius}m_max\": (\"passengers_2019\",\"max\"),\n",
        "            f\"station_passengers_{radius}m_mean\": (\"passengers_2019\",\"mean\")\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df = df.merge(feat, on=\"building_id\", how=\"left\")\n",
        "    for col in feat.columns:\n",
        "        if col != \"building_id\":\n",
        "            df[col] = df[col].fillna(0)\n",
        "            df[col + \"_log\"] = np.log1p(df[col])\n",
        "    return df"
      ],
      "metadata": {
        "id": "sUXL1k5Iqz2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 5. train/testに駅特徴量付与\n",
        "# =========================\n",
        "for radius in [500,1000]:\n",
        "    train = add_station_features(train, stations_gdf, radius)\n",
        "    test  = add_station_features(test, stations_gdf, radius)"
      ],
      "metadata": {
        "id": "OQWjRqnZq3mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4. 築年 → age（target_ymからyear_built）\n",
        "# year_builtはYYYYMM形式\n",
        "# =========================================================\n",
        "for df in [train,test]:\n",
        "    df[\"sale_year\"] = df[\"target_ym\"] // 100\n",
        "    df[\"age\"] = (df[\"sale_year\"] - (df[\"year_built\"] // 100)).clip(0,100)"
      ],
      "metadata": {
        "id": "YldeUXEiq5nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. 地価公示データ\n",
        "# =========================\n",
        "land_gdf = gpd.read_file(\"/content/L01-23.geojson\").to_crs(epsg=4326)\n",
        "for df in [train,test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "train_gdf = gpd.GeoDataFrame(train, geometry=\"geometry\", crs=\"EPSG:4326\").to_crs(epsg=6668)\n",
        "test_gdf  = gpd.GeoDataFrame(test,  geometry=\"geometry\", crs=\"EPSG:4326\").to_crs(epsg=6668)\n",
        "\n",
        "land_gdf  = land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "land_xy = np.vstack([land_gdf.geometry.x.values, land_gdf.geometry.y.values]).T\n",
        "tree = KDTree(land_xy)\n",
        "land_prices = land_gdf['L01_006'].values\n",
        "\n",
        "def nearest_land_price_fast(pt, tree, land_prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return land_prices[idx[0][0]]\n",
        "\n",
        "train_gdf['nearest_land_price'] = train_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "test_gdf['nearest_land_price']  = test_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "train['final_land_price'] = train_gdf['nearest_land_price'].values\n",
        "test['final_land_price']  = test_gdf['nearest_land_price'].values"
      ],
      "metadata": {
        "id": "7re7RBC_q7ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 6. 時期特徴量（年×マンション、年×首都圏、年×DID）\n",
        "# =========================================================\n",
        "CAPITAL_PREF_CODES = [13,14,12,11]  # 東京・神奈川・千葉・埼玉\n",
        "for df in [train,test]:\n",
        "    # base年は任意、ageに依存させるので安全\n",
        "    df[\"is_mansion\"] = (df[\"building_type\"] == 1).astype(int)\n",
        "    df[\"is_capital\"] = df[\"addr1_1\"].isin(CAPITAL_PREF_CODES).astype(int)\n",
        "    df[\"is_DID\"] = (df[\"DID_population\"] > 0).astype(int)\n",
        "\n",
        "    # 年×特徴量は age を使う\n",
        "    df[\"year_x_mansion\"] = df[\"age\"] * df[\"is_mansion\"]\n",
        "    df[\"year_x_capital\"] = df[\"age\"] * df[\"is_capital\"]\n",
        "    df[\"year_x_DID\"] = df[\"age\"] * df[\"is_DID\"]"
      ],
      "metadata": {
        "id": "sYz5h0qpJPri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. マンション/戸建てに分割\n",
        "# =========================\n",
        "train_mansion = train[train['building_type'] == 1].copy()\n",
        "train_house   = train[train['building_type'] == 4].copy()\n",
        "test_mansion  = test[test['building_type'] == 1].copy()\n",
        "test_house    = test[test['building_type'] == 4].copy()"
      ],
      "metadata": {
        "id": "QR2D8BTps1eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 8. 特徴量リスト\n",
        "# =========================================================\n",
        "common_features = [\n",
        "    'lon','lat',\n",
        "    'drugstore_distance','bank_distance','shopping_street_distance',\n",
        "    'parking_keiyaku','money_hoshou_company','free_rent_duration','free_rent_gen_timing',\n",
        "    'addr1','addr2','addr3','post1','post2',\"nearest_pref_land_price\",\n",
        "    \"nearest_pref_land_price_log\"\n",
        "]\n",
        "common_features += POP_COLS\n",
        "common_features += [\"year_x_capital\",\"year_x_DID\",\"age\"]\n",
        "\n",
        "mansion_features = common_features + [\n",
        "    'house_area','floor','room_count','total_units','building_structure','has_elevator','has_gym','maintenance_fee',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean',\n",
        "    'year_x_mansion'\n",
        "]\n",
        "\n",
        "house_features = common_features + [\n",
        "    'house_area','land_area','floor_count','room_count','building_structure',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean'\n",
        "]\n"
      ],
      "metadata": {
        "id": "XSH3UlBQs63P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 学習用データ作成関数\n",
        "# =========================\n",
        "\n",
        "DROP_COLS = [\n",
        "    \"building_id\",\n",
        "    \"money_room\",\n",
        "    \"money_hoshou_company\"\n",
        "]\n",
        "\n",
        "def prepare_Xy(df, features, is_train=True):\n",
        "    X = df[[c for c in features if c in df.columns]].copy()\n",
        "\n",
        "    # geometry が紛れ込んでも必ず落とす\n",
        "    if \"geometry\" in X.columns:\n",
        "        X = X.drop(columns=[\"geometry\"])\n",
        "\n",
        "    # 数値型だけに限定（最終防衛ライン）\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "    if is_train:\n",
        "        y = np.log1p(df[\"money_room\"])\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "X_mansion, y_mansion = prepare_Xy(train_mansion, mansion_features)\n",
        "X_house, y_house     = prepare_Xy(train_house, house_features)\n",
        "\n",
        "X_test_mansion = prepare_Xy(\n",
        "    test_mansion,\n",
        "    mansion_features,\n",
        "    is_train=False\n",
        ")\n",
        "\n",
        "X_test_house = prepare_Xy(\n",
        "    test_house,\n",
        "    house_features,\n",
        "    is_train=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "7Comaq9hqQ0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ##テスト！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
        "# fair_c_values = [0.05, 0.08, 0.1, 0.12, 0.15, 0.2]\n",
        "\n",
        "# def evaluate_fair_c_split(X, y, category_name='Mansion'):\n",
        "#     from sklearn.model_selection import train_test_split\n",
        "\n",
        "#     # train/valid分割\n",
        "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#     results = []\n",
        "#     for fair_c in fair_c_values:\n",
        "#         params = {\n",
        "#             'objective': 'fair',\n",
        "#             'metric': 'rmse',\n",
        "#             'boosting_type': 'gbdt',\n",
        "#             'num_leaves': 31,\n",
        "#             'fair_c': fair_c,\n",
        "#             'verbose': -1,\n",
        "#             'random_state': 42\n",
        "#         }\n",
        "\n",
        "#         train_data = lgb.Dataset(X_train, label=y_train)\n",
        "#         valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "\n",
        "#         model = lgb.train(\n",
        "#             params,\n",
        "#             train_data,\n",
        "#             num_boost_round=3000,\n",
        "#             valid_sets=[valid_data],\n",
        "#             early_stopping_rounds=200,\n",
        "#             verbose_eval=False\n",
        "#         )\n",
        "\n",
        "#         y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "#         mape = np.mean(np.abs((y_val - y_pred) / y_val))\n",
        "#         results.append((fair_c, mape))\n",
        "#         print(f\"{category_name} - fair_c: {fair_c:.2f}, MAPE: {mape:.6f}\")\n",
        "\n",
        "#     # 最良値\n",
        "#     best_fair_c, best_mape = min(results, key=lambda x: x[1])\n",
        "#     print(f\"==> {category_name} 最適 fair_c: {best_fair_c}, MAPE: {best_mape:.6f}\\n\")\n",
        "#     return results, (best_fair_c, best_mape)\n",
        "\n",
        "# # =========================================================\n",
        "# # マンション・戸建で評価\n",
        "# # =========================================================\n",
        "# print(\"マンション fair_c スキャン\")\n",
        "# mansion_results, mansion_best = evaluate_fair_c_split(X_mansion, y_mansion, 'マンション')\n",
        "\n",
        "# print(\"戸建 fair_c スキャン\")\n",
        "# house_results, house_best = evaluate_fair_c_split(X_house, y_house, '戸建')\n",
        "\n"
      ],
      "metadata": {
        "id": "ExJLI2KBSUX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 学習関数\n",
        "# =========================\n",
        "def train_lgb(X, y, seed):\n",
        "    model = lgb.LGBMRegressor(\n",
        "        n_estimators=5000,\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=64,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=seed,   # ★ ここが重要\n",
        "\n",
        "        objective=\"fair\",\n",
        "        fair_c=0.1,\n",
        "        min_child_samples=20,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1\n",
        "    )\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.2,\n",
        "        random_state=seed     # ★ split も seed 揃える\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_metric=\"mape\",\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(200),\n",
        "            lgb.log_evaluation(0)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "RLzwmUKeqUy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. モデル学習\n",
        "# =========================\n",
        "models_mansion = []\n",
        "models_house   = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"Training seed={seed}\")\n",
        "    models_mansion.append(train_lgb(X_mansion, y_mansion, seed))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGud5_oyqXXP",
        "outputId": "56f95271-e044-470d-9ada-7b7782fedb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training seed=42\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098138 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14786\n",
            "[LightGBM] [Info] Number of data points in the train set: 155660, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.925227\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00662085\tvalid_0's fair: 0.00459029\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078989 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12774\n",
            "[LightGBM] [Info] Number of data points in the train set: 121743, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.800475\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00879832\tvalid_0's fair: 0.00704314\n",
            "Training seed=100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132633 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14772\n",
            "[LightGBM] [Info] Number of data points in the train set: 155660, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.925363\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00661172\tvalid_0's fair: 0.00457847\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080563 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12777\n",
            "[LightGBM] [Info] Number of data points in the train set: 121743, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.799404\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00875192\tvalid_0's fair: 0.00698787\n",
            "Training seed=202\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100854 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14789\n",
            "[LightGBM] [Info] Number of data points in the train set: 155660, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.926939\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[4999]\tvalid_0's mape: 0.00664652\tvalid_0's fair: 0.00460416\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082023 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12788\n",
            "[LightGBM] [Info] Number of data points in the train set: 121743, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.799099\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00875531\tvalid_0's fair: 0.00699801\n",
            "Training seed=777\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.400627 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14783\n",
            "[LightGBM] [Info] Number of data points in the train set: 155660, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.925332\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00664984\tvalid_0's fair: 0.00462016\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.196434 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12769\n",
            "[LightGBM] [Info] Number of data points in the train set: 121743, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.799577\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00879688\tvalid_0's fair: 0.00701085\n",
            "Training seed=999\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096626 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 14768\n",
            "[LightGBM] [Info] Number of data points in the train set: 155660, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.925195\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00662717\tvalid_0's fair: 0.00459506\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125906 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12779\n",
            "[LightGBM] [Info] Number of data points in the train set: 121743, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.799115\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00874898\tvalid_0's fair: 0.00696485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. 学習時の列を保存\n",
        "# =========================\n",
        "cols_mansion = X_mansion.columns.tolist()\n",
        "cols_house   = X_house.columns.tolist()\n",
        "\n",
        "# =========================\n",
        "# アンサンブル予測関数\n",
        "# =========================\n",
        "def ensemble_predict(models, X):\n",
        "    preds = []\n",
        "    for model in models:\n",
        "        preds.append(model.predict(X))\n",
        "    return np.mean(preds, axis=0)\n"
      ],
      "metadata": {
        "id": "g_ByR_IU8bly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# test を building_type で3分割\n",
        "# =========================\n",
        "test_mansion = test[test[\"building_type\"] == 1].copy()\n",
        "test_house   = test[test[\"building_type\"] == 4].copy()\n",
        "test_other   = test[\n",
        "    ~test.index.isin(test_mansion.index) &\n",
        "    ~test.index.isin(test_house.index)\n",
        "].copy()"
      ],
      "metadata": {
        "id": "uDUK-gZf8e9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# test の特徴量を「学習時列」と完全一致\n",
        "# =========================\n",
        "X_test_mansion = test_mansion.reindex(\n",
        "    columns=cols_mansion,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "X_test_house = test_house.reindex(\n",
        "    columns=cols_house,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "X_test_other = test_other.reindex(\n",
        "    columns=cols_mansion,\n",
        "    fill_value=0\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "81tyKwPSqZjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##テスト！最適なスケール値を探す。全部コメント化\n",
        "\n",
        "# import numpy as np\n",
        "# from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "# # =========================\n",
        "# # 1. 予測値（補正前）を作成\n",
        "# # =========================\n",
        "# y_pred_mansion_raw = np.expm1(model_mansion.predict(X_mansion))\n",
        "# y_pred_house_raw   = np.expm1(model_house.predict(X_house))\n",
        "\n",
        "# y_true_mansion = np.expm1(y_mansion)\n",
        "# y_true_house   = np.expm1(y_house)\n",
        "\n",
        "# LOW_TH_MANSION = 9_000_000\n",
        "# LOW_TH_HOUSE   = 9_000_000\n",
        "\n",
        "# # =========================\n",
        "# # 2. 0.70 ~ 1.00 の範囲でスケールをテスト\n",
        "# # =========================\n",
        "# scales = np.arange(0.70, 1.01, 0.01)  # 0.01刻みで細かく探索\n",
        "\n",
        "# results_mansion = []\n",
        "# results_house   = []\n",
        "\n",
        "# for scale in scales:\n",
        "#     # --- マンション ---\n",
        "#     y_pred = y_pred_mansion_raw.copy()\n",
        "#     mask_low = y_pred <= LOW_TH_MANSION\n",
        "#     y_pred[mask_low] *= scale\n",
        "#     mape = mean_absolute_percentage_error(y_true_mansion, y_pred)\n",
        "#     results_mansion.append((scale, mape))\n",
        "\n",
        "#     # --- 戸建 ---\n",
        "#     y_pred = y_pred_house_raw.copy()\n",
        "#     mask_low = y_pred <= LOW_TH_HOUSE\n",
        "#     y_pred[mask_low] *= scale\n",
        "#     mape = mean_absolute_percentage_error(y_true_house, y_pred)\n",
        "#     results_house.append((scale, mape))\n",
        "\n",
        "# # =========================\n",
        "# # 3. 結果を確認\n",
        "# # =========================\n",
        "# results_mansion = sorted(results_mansion, key=lambda x: x[1])\n",
        "# results_house   = sorted(results_house, key=lambda x: x[1])\n",
        "\n",
        "# print(\"マンション: 最適スケールとMAPE上位5\")\n",
        "# for s, m in results_mansion[:5]:\n",
        "#     print(f\"scale={s:.2f}, MAPE={m:.6f}\")\n",
        "\n",
        "# print(\"\\n戸建: 最適スケールとMAPE上位5\")\n",
        "# for s, m in results_house[:5]:\n",
        "#     print(f\"scale={s:.2f}, MAPE={m:.6f}\")\n"
      ],
      "metadata": {
        "id": "HWvh7Rp0_u8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 低価格帯補正つき予測\n",
        "# =========================\n",
        "LOW_TH_MANSION = 9_000_000\n",
        "LOW_TH_HOUSE   = 9_000_000\n",
        "\n",
        "LOW_SCALE_MANSION = 0.98\n",
        "LOW_SCALE_HOUSE   = 0.98\n",
        "\n",
        "\n",
        "def predict_with_low_scale(model, X, low_th, low_scale):\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # まず予測値側をガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=20,   # log空間での上限\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # log → 元スケール\n",
        "    y_pred = np.expm1(y_pred)\n",
        "\n",
        "    # 再度ガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=1e9,\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # 下限クリップ\n",
        "    y_pred = np.clip(y_pred, 1, 1e9)\n",
        "\n",
        "    # 低価格帯補正\n",
        "    mask_low = y_pred <= low_th\n",
        "    y_pred[mask_low] *= low_scale\n",
        "\n",
        "    return y_pred\n",
        "#マンション\n",
        "y_pred_test_mansion_log = ensemble_predict(\n",
        "    models_mansion,\n",
        "    X_test_mansion\n",
        ")\n",
        "\n",
        "y_pred_test_mansion = np.expm1(y_pred_test_mansion_log)\n",
        "\n",
        "mask_low = y_pred_test_mansion <= LOW_TH_MANSION\n",
        "y_pred_test_mansion[mask_low] *= LOW_SCALE_MANSION\n",
        "\n",
        "#戸建て\n",
        "y_pred_test_house_log = ensemble_predict(\n",
        "    models_house,\n",
        "    X_test_house\n",
        ")\n",
        "\n",
        "y_pred_test_house = np.expm1(y_pred_test_house_log)\n",
        "\n",
        "mask_low = y_pred_test_house <= LOW_TH_HOUSE\n",
        "y_pred_test_house[mask_low] *= LOW_SCALE_HOUSE\n",
        "\n",
        "#other\n",
        "y_pred_test_other_log = ensemble_predict(\n",
        "    models_mansion,\n",
        "    X_test_other\n",
        ")\n",
        "\n",
        "y_pred_test_other = np.expm1(y_pred_test_other_log)\n",
        "\n",
        "mask_low = y_pred_test_other <= LOW_TH_MANSION\n",
        "y_pred_test_other[mask_low] *= LOW_SCALE_MANSION\n"
      ],
      "metadata": {
        "id": "aaM1NflE8neh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. test DataFrame に書き戻す\n",
        "# =========================\n",
        "test.loc[test_mansion.index, \"money_room\"] = y_pred_test_mansion\n",
        "test.loc[test_house.index,   \"money_room\"] = y_pred_test_house\n",
        "test.loc[test_other.index,   \"money_room\"] = y_pred_test_other\n",
        "\n",
        "test[\"money_room\"] = test[\"money_room\"].fillna(\n",
        "    test[\"money_room\"].median()\n",
        ")"
      ],
      "metadata": {
        "id": "TlSHkQ1hqcIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. submit.csv 作成\n",
        "# =========================\n",
        "submit = test[[\"id\", \"money_room\"]].sort_values(\"id\")\n",
        "submit.to_csv(\"submit.csv\", index=False, header=False)\n",
        "\n",
        "# NaN 確認\n",
        "import pandas as pd\n",
        "pd.read_csv(\"submit.csv\").isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "h_hPUSZp3t27",
        "outputId": "c224f974-ce5b-405f-b395-4ec90c2a05ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                     0\n",
              "14027808.173575142    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14027808.173575142</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# submit作成前に重複チェック\n",
        "test[['id']].duplicated().sum()\n",
        "# 0 なら id の重複はない\n"
      ],
      "metadata": {
        "id": "kwdYYm0LNWCw",
        "outputId": "bfd141f9-722f-4229-c751-dd1d7d4c1b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEAtrb6yXUOamjDwR78HqK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondonrocket/kokudo/blob/%E3%83%86%E3%82%B9%E3%83%88/hasegawa4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "a7Wc9jfop15s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import lightgbm as lgb\n",
        "from shapely.geometry import Point\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. train/test 読み込み\n",
        "# =========================\n",
        "train = pd.read_csv(\"/content/train.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)\n",
        "test  = pd.read_csv(\"/content/test.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)"
      ],
      "metadata": {
        "id": "322pg9pCqBZs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. year_built（年 or 年月）を正規化\n",
        "# =========================\n",
        "def normalize_year_month(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "\n",
        "    x = float(x)\n",
        "    year = int(x)\n",
        "    month = round((x - year) * 100)\n",
        "\n",
        "    if 1 <= month <= 12:\n",
        "        return year + month / 12\n",
        "    else:\n",
        "        return float(year)\n",
        "\n",
        "for df in [train, test]:\n",
        "    df[\"year_built_adj\"] = (\n",
        "        pd.to_numeric(df[\"year_built\"], errors=\"coerce\")\n",
        "        .apply(normalize_year_month)\n",
        "    )\n",
        "\n",
        "# =========================\n",
        "# 3. 新耐震フラグ（1981年基準）\n",
        "# =========================\n",
        "\n",
        "def classify_seismic(ym):\n",
        "  if pd.isna(ym):\n",
        "      return -1\n",
        "  if ym >= 198106:\n",
        "      return 2\n",
        "  elif ym >= 195012:\n",
        "      return 1\n",
        "  else:\n",
        "      return 0\n",
        "\n",
        "for df in [train, test]:\n",
        "    df[\"seismic_class\"] = df[\"year_built_adj\"].apply(classify_seismic)\n",
        "\n",
        "# =========================\n",
        "# 2. 築年数（age）\n",
        "# =========================\n",
        "CURRENT_YEAR = 2023\n",
        "\n",
        "for df in [train, test]:\n",
        "    df[\"age\"] = (CURRENT_YEAR - df[\"year_built_adj\"]).clip(0, 100)\n",
        "    df[\"age_sq\"] = df[\"age\"] ** 2\n",
        "    df[\"age_log\"] = np.log1p(df[\"age\"])\n",
        "    df[\"age_x_seismic\"] = df[\"age\"] * df[\"seismic_class\"]\n",
        "\n",
        "# =========================\n",
        "# 4. house_area 欠損処理（建物タイプ別）\n",
        "# =========================\n",
        "for df in [train, test]:\n",
        "    if \"house_area\" in df.columns:\n",
        "        df[\"house_area\"] = pd.to_numeric(df[\"house_area\"], errors=\"coerce\")\n",
        "\n",
        "        for bt in df[\"building_type\"].dropna().unique():\n",
        "            median_area = df.loc[df[\"building_type\"] == bt, \"house_area\"].median()\n",
        "            df.loc[\n",
        "                (df[\"building_type\"] == bt) & (df[\"house_area\"].isna()),\n",
        "                \"house_area\"\n",
        "            ] = median_area\n",
        "\n",
        "        # 最終ガード\n",
        "        df[\"house_area\"] = df[\"house_area\"].fillna(df[\"house_area\"].median())\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 6. house_area前処理\n",
        "# =========================\n",
        "for df in [train, test]:\n",
        "    df[\"house_area\"] = pd.to_numeric(df[\"house_area\"], errors=\"coerce\")\n",
        "    df[\"house_area\"] = df[\"house_area\"].fillna(df[\"house_area\"].median())"
      ],
      "metadata": {
        "id": "qp2sdE_e7ruL",
        "outputId": "97a5ad4a-a1a9-40fe-e458-e601fd333fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2783561853.py:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '71.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df.loc[\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# DID データ読み込み\n",
        "# =========================\n",
        "did_gdf = gpd.read_file(\"/content/A16-20_00_DID.shp\")\n",
        "\n",
        "# 人口・面積カラム\n",
        "DID_POP_COL  = \"A16_005\"\n",
        "DID_AREA_COL = \"A16_006\"\n",
        "\n",
        "# 密度\n",
        "did_gdf[\"DID_density\"] = did_gdf[DID_POP_COL] / (did_gdf[DID_AREA_COL] + 1e-6)\n",
        "\n",
        "# CRS統一\n",
        "did_gdf = did_gdf.to_crs(epsg=3857)\n",
        "\n",
        "#train / test を GeoDataFrame に変換\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=gpd.points_from_xy(train[\"lon\"], train[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=gpd.points_from_xy(test[\"lon\"], test[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ").to_crs(epsg=3857)\n",
        "\n",
        "#KDTree用の座標準備\n",
        "# DIDポリゴンの代表点（centroid）\n",
        "did_coords = np.vstack([\n",
        "    did_gdf.geometry.centroid.x,\n",
        "    did_gdf.geometry.centroid.y\n",
        "]).T\n",
        "\n",
        "tree = KDTree(did_coords)\n",
        "\n",
        "#最近傍DIDを割り当てる関数\n",
        "def attach_DID_features(base_gdf, did_gdf, tree):\n",
        "    coords = np.vstack([\n",
        "        base_gdf.geometry.x,\n",
        "        base_gdf.geometry.y\n",
        "    ]).T\n",
        "\n",
        "    _, idx = tree.query(coords, k=1)\n",
        "\n",
        "    base_gdf[\"DID_population\"] = did_gdf.iloc[idx.flatten()][DID_POP_COL].values\n",
        "    base_gdf[\"DID_area\"]       = did_gdf.iloc[idx.flatten()][DID_AREA_COL].values\n",
        "    base_gdf[\"DID_density\"]    = did_gdf.iloc[idx.flatten()][\"DID_density\"].values\n",
        "\n",
        "    return base_gdf\n",
        "\n",
        "#train / test にDID付与\n",
        "train_gdf = attach_DID_features(train_gdf, did_gdf, tree)\n",
        "test_gdf  = attach_DID_features(test_gdf,  did_gdf, tree)\n",
        "\n",
        "#geometryを落として DataFrame に戻す\n",
        "train = pd.DataFrame(train_gdf.drop(columns=\"geometry\"))\n",
        "test  = pd.DataFrame(test_gdf.drop(columns=\"geometry\"))\n",
        "\n",
        "#欠損処理\n",
        "for col in [\"DID_population\", \"DID_area\", \"DID_density\"]:\n",
        "    train[col] = train[col].fillna(0)\n",
        "    test[col]  = test[col].fillna(0)\n",
        "\n",
        "    train[f\"{col}_log\"] = np.log1p(train[col])\n",
        "    test[f\"{col}_log\"]  = np.log1p(test[col])\n",
        "\n",
        "#house_area × DID\n",
        "for df in [train, test]:\n",
        "    df[\"area_weighted_by_urban\"] = df[\"house_area\"] * (\n",
        "        1 + df[\"DID_density_log\"]\n",
        "    )\n",
        "\n",
        "#特徴量に追加\n",
        "did_area_features = [\n",
        "    \"DID_population\",\n",
        "    \"DID_area\",\n",
        "    \"DID_density\",\n",
        "    \"DID_density_log\",\n",
        "    \"area_x_log_DID_density\",\n",
        "    \"area_weighted_by_urban\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "5GX6zgeQqr9W"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 駅乗降客数（2019年）\n",
        "# =========================\n",
        "df = pd.read_csv(\"S12-24_NumberOfPassengers_utf8.csv\")\n",
        "df_2019 = df[(df[\"S12_039\"]==1)&(df[\"S12_038\"]==1)]\n",
        "station_2019 = df_2019.groupby(\"S12_001c\", as_index=False).agg(passengers_2019=(\"S12_041\",\"sum\")).rename(columns={\"S12_001c\":\"station_code\"})\n"
      ],
      "metadata": {
        "id": "lSMvSRsVqs4T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 3. 駅ポイント（lon / lat）\n",
        "# =========================\n",
        "station_point_gdf = gpd.read_file(\"/content/S12-24_NumberOfPassengers.geojson\")\n",
        "station_point_gdf[\"S12_001c\"] = station_point_gdf[\"S12_001c\"].astype(str)\n",
        "station_2019[\"station_code\"] = station_2019[\"station_code\"].astype(str)\n",
        "stations = station_point_gdf.merge(station_2019, left_on=\"S12_001c\", right_on=\"station_code\", how=\"left\")\n",
        "stations = stations.to_crs(epsg=3857)\n",
        "stations[\"geometry\"] = stations.geometry.centroid\n",
        "stations_gdf = stations[[\"S12_001c\",\"passengers_2019\",\"geometry\"]].copy()\n",
        "stations_gdf.crs = \"EPSG:3857\""
      ],
      "metadata": {
        "id": "pRiaY6GRqw4O"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 駅特徴量作成関数\n",
        "# =========================\n",
        "def add_station_features(df, stations_gdf, radius=500):\n",
        "    df = df.copy()\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
        "\n",
        "    # 既存の index_right を削除\n",
        "    if \"index_right\" in gdf.columns:\n",
        "        gdf = gdf.drop(columns=[\"index_right\"])\n",
        "    if \"index_right\" in stations_gdf.columns:\n",
        "        stations_gdf = stations_gdf.drop(columns=[\"index_right\"])\n",
        "\n",
        "    joined = gpd.sjoin(gdf, stations_gdf, how=\"left\", predicate=\"dwithin\", distance=radius)\n",
        "\n",
        "    feat = joined.groupby(\"building_id\", as_index=False).agg(\n",
        "        **{\n",
        "            f\"station_passengers_{radius}m_sum\": (\"passengers_2019\",\"sum\"),\n",
        "            f\"station_passengers_{radius}m_max\": (\"passengers_2019\",\"max\"),\n",
        "            f\"station_passengers_{radius}m_mean\": (\"passengers_2019\",\"mean\")\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df = df.merge(feat, on=\"building_id\", how=\"left\")\n",
        "    for col in feat.columns:\n",
        "        if col != \"building_id\":\n",
        "            df[col] = df[col].fillna(0)\n",
        "            df[col + \"_log\"] = np.log1p(df[col])\n",
        "    return df"
      ],
      "metadata": {
        "id": "sUXL1k5Iqz2W"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 5. train/testに駅特徴量付与\n",
        "# =========================\n",
        "for radius in [500,1000]:\n",
        "    train = add_station_features(train, stations_gdf, radius)\n",
        "    test  = add_station_features(test, stations_gdf, radius)"
      ],
      "metadata": {
        "id": "OQWjRqnZq3mu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. 地価公示データ\n",
        "# =========================\n",
        "land_gdf = gpd.read_file(\"/content/L01-23.geojson\").to_crs(epsg=4326)\n",
        "for df in [train,test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "train_gdf = gpd.GeoDataFrame(train, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "test_gdf  = gpd.GeoDataFrame(test, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "train_gdf = train_gdf.to_crs(epsg=6668)\n",
        "test_gdf  = test_gdf.to_crs(epsg=6668)\n",
        "land_gdf  = land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "land_xy = np.vstack([land_gdf.geometry.x.values, land_gdf.geometry.y.values]).T\n",
        "tree = KDTree(land_xy)\n",
        "land_prices = land_gdf['L01_006'].values\n",
        "\n",
        "def nearest_land_price_fast(pt, tree, land_prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return land_prices[idx[0][0]]\n",
        "\n",
        "train_gdf['nearest_land_price'] = train_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "test_gdf['nearest_land_price']  = test_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "train['final_land_price'] = train_gdf['nearest_land_price'].values\n",
        "test['final_land_price']  = test_gdf['nearest_land_price'].values"
      ],
      "metadata": {
        "id": "7re7RBC_q7ZC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. マンション/戸建てに分割\n",
        "# =========================\n",
        "train_mansion = train[train['building_type'] == 1].copy()\n",
        "train_house   = train[train['building_type'] == 4].copy()\n",
        "test_mansion  = test[test['building_type'] == 1].copy()\n",
        "test_house    = test[test['building_type'] == 4].copy()"
      ],
      "metadata": {
        "id": "QR2D8BTps1eT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 共通特徴量\n",
        "# =========================\n",
        "common_features = [\n",
        "    'target_ym','lon','lat',\n",
        "    'drugstore_distance','bank_distance','shopping_street_distance',\n",
        "    'parking_keiyaku','money_hoshou_company','free_rent_duration','free_rent_gen_timing',\n",
        "        'year_built_adj','age','seismic_class','age','age_sq','age_log','age_x_seismic'\n",
        "]\n",
        "\n",
        "mansion_features = common_features + [\n",
        "    'house_area','floor','room_count','total_units','building_structure','has_elevator','has_gym','maintenance_fee',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean',\"DID_density_log\",\"area_x_log_DID_density\",\"area_weighted_by_urban\"\n",
        "]\n",
        "\n",
        "house_features = common_features + [\n",
        "    'house_area','land_area','floor_count','room_count','building_structure',\n",
        "    'DID_population','DID_area','DID_density','final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean',\"DID_density_log\",\"area_x_log_DID_density\",\"area_weighted_by_urban\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "XSH3UlBQs63P"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 学習用データ作成関数\n",
        "# =========================\n",
        "\n",
        "DROP_COLS = [\n",
        "    \"id\",\n",
        "    \"money_room\",\n",
        "    \"money_hoshou_company\"\n",
        "]\n",
        "\n",
        "def make_features(df):\n",
        "    return [\n",
        "        c for c in df.columns\n",
        "        if c not in DROP_COLS\n",
        "        and df[c].dtype != \"object\"\n",
        "    ]\n",
        "\n",
        "mansion_features = make_features(train_mansion)\n",
        "house_features   = make_features(train_house)\n",
        "\n",
        "def prepare_Xy(df, features, is_train=True):\n",
        "    X = df[[c for c in features if c in df.columns]].copy()\n",
        "\n",
        "    # geometry が紛れ込んでも必ず落とす\n",
        "    if \"geometry\" in X.columns:\n",
        "        X = X.drop(columns=[\"geometry\"])\n",
        "\n",
        "    # 数値型だけに限定（最終防衛ライン）\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "    if is_train:\n",
        "        y = np.log1p(df[\"money_room\"])\n",
        "        return X, y\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "X_mansion, y_mansion = prepare_Xy(train_mansion, mansion_features)\n",
        "X_house, y_house     = prepare_Xy(train_house, house_features)\n",
        "\n",
        "X_test_mansion = test_mansion[mansion_features].copy()\n",
        "X_test_house   = test_house[house_features].copy()\n",
        "\n"
      ],
      "metadata": {
        "id": "7Comaq9hqQ0U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 学習関数\n",
        "# =========================\n",
        "def train_lgb(X, y):\n",
        "    model = lgb.LGBMRegressor(\n",
        "        n_estimators=5000,\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=64,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "\n",
        "        # Kaggle向け設定\n",
        "        objective=\"fair\",\n",
        "        fair_c=0.1,          # ★ 0.8から変更\n",
        "        min_child_samples=20,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=0.1\n",
        "    )\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y,\n",
        "        test_size=0.2,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_metric=\"mape\",\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(200),\n",
        "            lgb.log_evaluation(200)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "RLzwmUKeqUy0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. モデル学習\n",
        "# =========================\n",
        "model_mansion = train_lgb(X_mansion, y_mansion)\n",
        "model_house   = train_lgb(X_house, y_house)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGud5_oyqXXP",
        "outputId": "fa187508-cbd1-40f5-88a7-7adee81ca8d6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.587373 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 14783\n",
            "[LightGBM] [Info] Number of data points in the train set: 155669, number of used features: 108\n",
            "[LightGBM] [Info] Start training from score 16.925193\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's mape: 0.00882298\tvalid_0's fair: 0.00686797\n",
            "[400]\tvalid_0's mape: 0.00817808\tvalid_0's fair: 0.00617103\n",
            "[600]\tvalid_0's mape: 0.00788123\tvalid_0's fair: 0.00585501\n",
            "[800]\tvalid_0's mape: 0.00770078\tvalid_0's fair: 0.00566647\n",
            "[1000]\tvalid_0's mape: 0.00756459\tvalid_0's fair: 0.00552488\n",
            "[1200]\tvalid_0's mape: 0.00745495\tvalid_0's fair: 0.00541235\n",
            "[1400]\tvalid_0's mape: 0.00736507\tvalid_0's fair: 0.00531996\n",
            "[1600]\tvalid_0's mape: 0.00728267\tvalid_0's fair: 0.0052371\n",
            "[1800]\tvalid_0's mape: 0.00721277\tvalid_0's fair: 0.00516684\n",
            "[2000]\tvalid_0's mape: 0.00714676\tvalid_0's fair: 0.00510198\n",
            "[2200]\tvalid_0's mape: 0.00709027\tvalid_0's fair: 0.00504807\n",
            "[2400]\tvalid_0's mape: 0.00704115\tvalid_0's fair: 0.00500005\n",
            "[2600]\tvalid_0's mape: 0.0069974\tvalid_0's fair: 0.00495792\n",
            "[2800]\tvalid_0's mape: 0.00695969\tvalid_0's fair: 0.00492299\n",
            "[3000]\tvalid_0's mape: 0.00692367\tvalid_0's fair: 0.00488896\n",
            "[3200]\tvalid_0's mape: 0.00688936\tvalid_0's fair: 0.00485646\n",
            "[3400]\tvalid_0's mape: 0.00685541\tvalid_0's fair: 0.00482451\n",
            "[3600]\tvalid_0's mape: 0.00682582\tvalid_0's fair: 0.00479635\n",
            "[3800]\tvalid_0's mape: 0.0067981\tvalid_0's fair: 0.00477123\n",
            "[4000]\tvalid_0's mape: 0.00677326\tvalid_0's fair: 0.00474805\n",
            "[4200]\tvalid_0's mape: 0.00675008\tvalid_0's fair: 0.00472642\n",
            "[4400]\tvalid_0's mape: 0.0067307\tvalid_0's fair: 0.0047078\n",
            "[4600]\tvalid_0's mape: 0.00670901\tvalid_0's fair: 0.00468723\n",
            "[4800]\tvalid_0's mape: 0.00668695\tvalid_0's fair: 0.00466695\n",
            "[5000]\tvalid_0's mape: 0.00666733\tvalid_0's fair: 0.0046487\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00666733\tvalid_0's fair: 0.0046487\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077263 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 12746\n",
            "[LightGBM] [Info] Number of data points in the train set: 122764, number of used features: 105\n",
            "[LightGBM] [Info] Start training from score 16.798816\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\tvalid_0's mape: 0.0117514\tvalid_0's fair: 0.0102388\n",
            "[400]\tvalid_0's mape: 0.0110739\tvalid_0's fair: 0.00945068\n",
            "[600]\tvalid_0's mape: 0.0107271\tvalid_0's fair: 0.00905653\n",
            "[800]\tvalid_0's mape: 0.0104875\tvalid_0's fair: 0.00878905\n",
            "[1000]\tvalid_0's mape: 0.0103063\tvalid_0's fair: 0.00858904\n",
            "[1200]\tvalid_0's mape: 0.0101557\tvalid_0's fair: 0.00842564\n",
            "[1400]\tvalid_0's mape: 0.0100179\tvalid_0's fair: 0.00827689\n",
            "[1600]\tvalid_0's mape: 0.00989528\tvalid_0's fair: 0.0081448\n",
            "[1800]\tvalid_0's mape: 0.00978833\tvalid_0's fair: 0.00803332\n",
            "[2000]\tvalid_0's mape: 0.00969173\tvalid_0's fair: 0.00793261\n",
            "[2200]\tvalid_0's mape: 0.00960734\tvalid_0's fair: 0.0078457\n",
            "[2400]\tvalid_0's mape: 0.00953003\tvalid_0's fair: 0.00776747\n",
            "[2600]\tvalid_0's mape: 0.00945933\tvalid_0's fair: 0.00769484\n",
            "[2800]\tvalid_0's mape: 0.00939006\tvalid_0's fair: 0.00762462\n",
            "[3000]\tvalid_0's mape: 0.00932868\tvalid_0's fair: 0.00756248\n",
            "[3200]\tvalid_0's mape: 0.00927216\tvalid_0's fair: 0.0075057\n",
            "[3400]\tvalid_0's mape: 0.00922094\tvalid_0's fair: 0.00745383\n",
            "[3600]\tvalid_0's mape: 0.00917125\tvalid_0's fair: 0.00740346\n",
            "[3800]\tvalid_0's mape: 0.00912455\tvalid_0's fair: 0.00735668\n",
            "[4000]\tvalid_0's mape: 0.00908376\tvalid_0's fair: 0.00731606\n",
            "[4200]\tvalid_0's mape: 0.00904415\tvalid_0's fair: 0.00727645\n",
            "[4400]\tvalid_0's mape: 0.00900703\tvalid_0's fair: 0.0072394\n",
            "[4600]\tvalid_0's mape: 0.00896991\tvalid_0's fair: 0.00720226\n",
            "[4800]\tvalid_0's mape: 0.00893619\tvalid_0's fair: 0.00716896\n",
            "[5000]\tvalid_0's mape: 0.00890221\tvalid_0's fair: 0.00713533\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\tvalid_0's mape: 0.00890221\tvalid_0's fair: 0.00713533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. 学習時の列を保存\n",
        "# =========================\n",
        "cols_mansion = X_mansion.columns.tolist()\n",
        "cols_house   = X_house.columns.tolist()"
      ],
      "metadata": {
        "id": "g_ByR_IU8bly"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. test の列を学習時と完全一致させる\n",
        "# =========================\n",
        "X_test_mansion = X_test_mansion.reindex(\n",
        "    columns=cols_mansion,\n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "X_test_house = X_test_house.reindex(\n",
        "    columns=cols_house,\n",
        "    fill_value=0\n",
        ")"
      ],
      "metadata": {
        "id": "uDUK-gZf8e9W"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 低価格帯補正つき予測\n",
        "# =========================\n",
        "LOW_TH_MANSION = 9_000_000\n",
        "LOW_TH_HOUSE   = 9_000_000\n",
        "\n",
        "LOW_SCALE_MANSION = 0.83\n",
        "LOW_SCALE_HOUSE   = 0.83\n",
        "\n",
        "\n",
        "def predict_with_low_scale(model, X, low_th, low_scale):\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # まず予測値側をガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=20,   # log空間での上限\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # log → 元スケール\n",
        "    y_pred = np.expm1(y_pred)\n",
        "\n",
        "    # 再度ガード\n",
        "    y_pred = np.nan_to_num(\n",
        "        y_pred,\n",
        "        nan=0.0,\n",
        "        posinf=1e9,\n",
        "        neginf=0.0\n",
        "    )\n",
        "\n",
        "    # 下限クリップ\n",
        "    y_pred = np.clip(y_pred, 1, 1e9)\n",
        "\n",
        "    # 低価格帯補正\n",
        "    mask_low = y_pred <= low_th\n",
        "    y_pred[mask_low] *= low_scale\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "\n",
        "y_pred_test_mansion = predict_with_low_scale(\n",
        "    model_mansion,\n",
        "    X_test_mansion,\n",
        "    LOW_TH_MANSION,\n",
        "    LOW_SCALE_MANSION\n",
        ")\n",
        "\n",
        "y_pred_test_house = predict_with_low_scale(\n",
        "    model_house,\n",
        "    X_test_house,\n",
        "    LOW_TH_HOUSE,\n",
        "    LOW_SCALE_HOUSE\n",
        ")"
      ],
      "metadata": {
        "id": "81tyKwPSqZjT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. test DataFrame に書き戻す\n",
        "# =========================\n",
        "test.loc[test_mansion.index, \"money_room\"] = y_pred_test_mansion\n",
        "test.loc[test_house.index,   \"money_room\"] = y_pred_test_house\n",
        "\n",
        "mask_other = test[\"money_room\"].isna()\n",
        "\n",
        "X_other = test.loc[mask_other].reindex(columns=cols_mansion, fill_value=0)\n",
        "\n",
        "test.loc[mask_other, \"money_room\"] = predict_with_low_scale(\n",
        "    model_mansion, X_other, LOW_TH_MANSION, LOW_SCALE_MANSION\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 8. 最終ガード（超重要）\n",
        "# =========================\n",
        "test[\"money_room\"] = (\n",
        "    test[\"money_room\"]\n",
        "    .replace([np.inf, -np.inf], np.nan)\n",
        "    .fillna(test[\"money_room\"].median())\n",
        "    .clip(1, 1e9)\n",
        ")"
      ],
      "metadata": {
        "id": "aaM1NflE8neh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. submit.csv 作成\n",
        "# =========================\n",
        "submit = test[[\"id\", \"money_room\"]].sort_values(\"id\")\n",
        "submit.to_csv(\"submit.csv\", index=False, header=False)\n",
        "\n",
        "print(\"submit.csv を出力しました\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlSHkQ1hqcIM",
        "outputId": "89132f8c-eac9-4944-eaa0-b0fd8e57e5ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submit.csv を出力しました\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/submit.csv\")\n",
        "\n",
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_hPUSZp3t27",
        "outputId": "430cc36b-a0e8-4c05-a9de-acf574d5ea30"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}
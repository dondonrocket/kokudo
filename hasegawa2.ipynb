{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPo2ulrzDvMjnmwrCpV5gXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dondonrocket/kokudo/blob/%E3%83%9E%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%B3%E3%80%81%E6%88%B8%E5%BB%BA%E3%81%A6%E5%88%86%E3%81%91%E3%81%A6/hasegawa2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7Wc9jfop15s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import lightgbm as lgb\n",
        "from shapely.geometry import Point\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KDTree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0. train/test 読み込み\n",
        "# =========================\n",
        "train = pd.read_csv(\"/content/train.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)\n",
        "test  = pd.read_csv(\"/content/test.csv\", encoding=\"shift_jis\", encoding_errors=\"replace\", low_memory=False)"
      ],
      "metadata": {
        "id": "322pg9pCqBZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# DID\n",
        "# =========================\n",
        "\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "# =========================\n",
        "# 1. DID shp 読み込み\n",
        "# =========================\n",
        "did_gdf = gpd.read_file(\"/content/A16-20_00_DID.shp\")  # アップロードした shp\n",
        "did_gdf = did_gdf.to_crs(epsg=4326)  # train/test と CRS を合わせる\n",
        "\n",
        "# DID の識別子列\n",
        "did_id_col = \"A16_001\"\n",
        "\n",
        "# 参考に人口や面積の列を選定\n",
        "did_pop_col = \"A16_005\"  # 人口\n",
        "did_area_col = \"A16_006\"  # 面積\n",
        "did_gdf[\"DID_density\"] = did_gdf[did_pop_col] / (did_gdf[did_area_col] + 1e-6)\n",
        "\n",
        "# =========================\n",
        "# 2. train/test GeoDataFrame化\n",
        "# =========================\n",
        "train_gdf = gpd.GeoDataFrame(\n",
        "    train,\n",
        "    geometry=gpd.points_from_xy(train[\"lon\"], train[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "test_gdf = gpd.GeoDataFrame(\n",
        "    test,\n",
        "    geometry=gpd.points_from_xy(test[\"lon\"], test[\"lat\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 3. 空間結合: DID 割り当て\n",
        "# =========================\n",
        "train_gdf = gpd.sjoin(train_gdf, did_gdf[[did_id_col, did_pop_col, did_area_col, \"DID_density\", \"geometry\"]], how=\"left\", predicate=\"within\")\n",
        "test_gdf  = gpd.sjoin(test_gdf,  did_gdf[[did_id_col, did_pop_col, did_area_col, \"DID_density\", \"geometry\"]], how=\"left\", predicate=\"within\")\n",
        "\n",
        "# 列名を整える\n",
        "train_gdf.rename(columns={\n",
        "    did_pop_col: \"DID_population\",\n",
        "    did_area_col: \"DID_area\"\n",
        "}, inplace=True)\n",
        "test_gdf.rename(columns={\n",
        "    did_pop_col: \"DID_population\",\n",
        "    did_area_col: \"DID_area\"\n",
        "}, inplace=True)\n",
        "\n",
        "# =========================\n",
        "# 4. 欠損処理\n",
        "# =========================\n",
        "for col in [\"DID_population\", \"DID_area\", \"DID_density\"]:\n",
        "    train_gdf[col] = train_gdf[col].fillna(0)\n",
        "    test_gdf[col]  = test_gdf[col].fillna(0)\n",
        "\n",
        "# =========================\n",
        "# 5. train/test に反映\n",
        "# =========================\n",
        "train = pd.DataFrame(train_gdf.drop(columns=\"geometry\"))\n",
        "test  = pd.DataFrame(test_gdf.drop(columns=\"geometry\"))\n",
        "\n",
        "# 確認\n",
        "train[[\"DID_population\", \"DID_area\", \"DID_density\"]].head()\n",
        "\n",
        "# =========================\n",
        "# DID特徴量をtrain/testに結合\n",
        "# =========================\n",
        "# 例: DID_population, DID_area, DID_density\n",
        "# DIDのGeoDataFrameを gpd.read_file(\"DID.shp\") で読み込んでいる前提\n",
        "# train/testのgeometryはすでにEPSG:4326になっていると仮定\n",
        "\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# =========================\n",
        "# DID特徴量をKDTreeで割り当てる関数（修正版）\n",
        "# =========================\n",
        "def add_DID_features(df, df_geometry, did_gdf, did_columns=[\"A16_005\",\"A16_006\",\"A16_010\"]):\n",
        "    \"\"\"\n",
        "    df: train/testのDataFrame\n",
        "    df_geometry: df のジオメトリ列 (すでにEPSG:3857で座標系変換済み)\n",
        "    did_gdf: DIDのGeoDataFrame (EPSG:3857)\n",
        "    did_columns: 割り当てる列名\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    # DIDの重心座標\n",
        "    did_xy = np.vstack([did_gdf.geometry.centroid.x, did_gdf.geometry.centroid.y]).T\n",
        "    tree = KDTree(did_xy)\n",
        "\n",
        "    # 最も近いDIDインデックスを取得\n",
        "    assigned = []\n",
        "    for pt in df_geometry:\n",
        "        dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "        assigned.append(idx[0][0])\n",
        "\n",
        "    assigned_df = did_gdf.iloc[assigned][did_columns].reset_index(drop=True)\n",
        "    assigned_df.index = df.index\n",
        "    df[did_columns] = assigned_df\n",
        "    return df\n",
        "\n",
        "# =========================\n",
        "# EPSG:3857に変換して使用\n",
        "# =========================\n",
        "train_gdf_3857 = train_gdf.to_crs(epsg=3857)\n",
        "test_gdf_3857  = test_gdf.to_crs(epsg=3857)\n",
        "did_gdf_3857   = did_gdf.to_crs(epsg=3857)\n",
        "\n",
        "# train/test に割り当て\n",
        "train = add_DID_features(train, train_gdf_3857.geometry, did_gdf_3857, did_columns=[\"A16_005\",\"A16_006\",\"A16_010\"])\n",
        "test  = add_DID_features(test,  test_gdf_3857.geometry,  did_gdf_3857, did_columns=[\"A16_005\",\"A16_006\",\"A16_010\"])\n"
      ],
      "metadata": {
        "id": "5GX6zgeQqr9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 駅乗降客数（2019年）\n",
        "# =========================\n",
        "df = pd.read_csv(\"S12-24_NumberOfPassengers_utf8.csv\")\n",
        "df_2019 = df[(df[\"S12_039\"]==1)&(df[\"S12_038\"]==1)]\n",
        "station_2019 = df_2019.groupby(\"S12_001c\", as_index=False).agg(passengers_2019=(\"S12_041\",\"sum\")).rename(columns={\"S12_001c\":\"station_code\"})\n",
        ""
      ],
      "metadata": {
        "id": "lSMvSRsVqs4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 3. 駅ポイント（lon / lat）\n",
        "# =========================\n",
        "station_point_gdf = gpd.read_file(\"/content/S12-24_NumberOfPassengers.geojson\")\n",
        "station_point_gdf[\"S12_001c\"] = station_point_gdf[\"S12_001c\"].astype(str)\n",
        "station_2019[\"station_code\"] = station_2019[\"station_code\"].astype(str)\n",
        "stations = station_point_gdf.merge(station_2019, left_on=\"S12_001c\", right_on=\"station_code\", how=\"left\")\n",
        "stations = stations.to_crs(epsg=3857)\n",
        "stations[\"geometry\"] = stations.geometry.centroid\n",
        "stations_gdf = stations[[\"S12_001c\",\"passengers_2019\",\"geometry\"]].copy()\n",
        "stations_gdf.crs = \"EPSG:3857\""
      ],
      "metadata": {
        "id": "pRiaY6GRqw4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 駅特徴量作成関数\n",
        "# =========================\n",
        "def add_station_features(df, stations_gdf, radius=500):\n",
        "    df = df.copy()\n",
        "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
        "\n",
        "    # 既存の index_right を削除\n",
        "    if \"index_right\" in gdf.columns:\n",
        "        gdf = gdf.drop(columns=[\"index_right\"])\n",
        "    if \"index_right\" in stations_gdf.columns:\n",
        "        stations_gdf = stations_gdf.drop(columns=[\"index_right\"])\n",
        "\n",
        "    joined = gpd.sjoin(gdf, stations_gdf, how=\"left\", predicate=\"dwithin\", distance=radius)\n",
        "\n",
        "    feat = joined.groupby(\"building_id\", as_index=False).agg(\n",
        "        **{\n",
        "            f\"station_passengers_{radius}m_sum\": (\"passengers_2019\",\"sum\"),\n",
        "            f\"station_passengers_{radius}m_max\": (\"passengers_2019\",\"max\"),\n",
        "            f\"station_passengers_{radius}m_mean\": (\"passengers_2019\",\"mean\")\n",
        "        }\n",
        "    )\n",
        "\n",
        "    df = df.merge(feat, on=\"building_id\", how=\"left\")\n",
        "    for col in feat.columns:\n",
        "        if col != \"building_id\":\n",
        "            df[col] = df[col].fillna(0)\n",
        "            df[col + \"_log\"] = np.log1p(df[col])\n",
        "    return df"
      ],
      "metadata": {
        "id": "sUXL1k5Iqz2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 5. train/testに駅特徴量付与\n",
        "# =========================\n",
        "for radius in [500,1000]:\n",
        "    train = add_station_features(train, stations_gdf, radius)\n",
        "    test  = add_station_features(test, stations_gdf, radius)"
      ],
      "metadata": {
        "id": "OQWjRqnZq3mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 6. 築年 → 築年数\n",
        "# =========================\n",
        "for df in [train,test]:\n",
        "    df[\"building_create_date\"] = pd.to_numeric(df[\"building_create_date\"], errors=\"coerce\")\n",
        "    df[\"age\"] = (2023 - df[\"building_create_date\"]).clip(0,100)\n"
      ],
      "metadata": {
        "id": "YldeUXEiq5nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. 地価公示データ\n",
        "# =========================\n",
        "land_gdf = gpd.read_file(\"/content/L01-23.geojson\").to_crs(epsg=4326)\n",
        "for df in [train,test]:\n",
        "    df[\"geometry\"] = gpd.points_from_xy(df[\"lon\"], df[\"lat\"])\n",
        "train_gdf = gpd.GeoDataFrame(train, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "test_gdf  = gpd.GeoDataFrame(test, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
        "train_gdf = train_gdf.to_crs(epsg=6668)\n",
        "test_gdf  = test_gdf.to_crs(epsg=6668)\n",
        "land_gdf  = land_gdf.to_crs(epsg=6668)\n",
        "\n",
        "land_xy = np.vstack([land_gdf.geometry.x.values, land_gdf.geometry.y.values]).T\n",
        "tree = KDTree(land_xy)\n",
        "land_prices = land_gdf['L01_006'].values\n",
        "\n",
        "def nearest_land_price_fast(pt, tree, land_prices):\n",
        "    dist, idx = tree.query([[pt.x, pt.y]], k=1)\n",
        "    return land_prices[idx[0][0]]\n",
        "\n",
        "train_gdf['nearest_land_price'] = train_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "test_gdf['nearest_land_price']  = test_gdf['geometry'].apply(lambda pt: nearest_land_price_fast(pt, tree, land_prices))\n",
        "train['final_land_price'] = train_gdf['nearest_land_price'].values\n",
        "test['final_land_price']  = test_gdf['nearest_land_price'].values"
      ],
      "metadata": {
        "id": "7re7RBC_q7ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. マンション/戸建てに分割\n",
        "# =========================\n",
        "train_mansion = train[train['building_type'] == 1].copy()\n",
        "train_house   = train[train['building_type'] == 4].copy()\n",
        "test_mansion  = test[test['building_type'] == 1].copy()\n",
        "test_house    = test[test['building_type'] == 4].copy()"
      ],
      "metadata": {
        "id": "QR2D8BTps1eT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. 共通特徴量\n",
        "# =========================\n",
        "common_features = [\n",
        "    'target_ym',\n",
        "    'lon','lat',\n",
        "    'drugstore_distance','bank_distance','shopping_street_distance',\n",
        "    'parking_keiyaku','money_hoshou_company','free_rent_duration','free_rent_gen_timing',\n",
        "    'addr1','addr2','addr3','post1','post2'\n",
        "]\n",
        "\n",
        "# マンション特徴量\n",
        "mansion_features = common_features + [\n",
        "    'house_area','floor','room_count','total_units','building_structure','has_elevator','has_gym','maintenance_fee',\n",
        "    'DID_population','DID_area','DID_density',\n",
        "    'final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean'\n",
        "]\n",
        "\n",
        "# 戸建て特徴量\n",
        "house_features = common_features + [\n",
        "    'house_area','land_area','floor_count','room_count','building_structure',\n",
        "    'DID_population','DID_area','DID_density',\n",
        "    'final_land_price',\n",
        "    'station_passengers_500m_sum','station_passengers_500m_max','station_passengers_500m_mean',\n",
        "    'station_passengers_1000m_sum','station_passengers_1000m_max','station_passengers_1000m_mean'\n",
        "]"
      ],
      "metadata": {
        "id": "XSH3UlBQs63P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. 学習用データ作成関数\n",
        "# =========================\n",
        "def prepare_Xy(df, features):\n",
        "    y = np.log1p(df[\"money_room\"])\n",
        "    X = df[features].copy()\n",
        "    # 数値列のみ\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "    return X, y\n",
        "\n",
        "X_mansion, y_mansion = prepare_Xy(train_mansion, mansion_features)\n",
        "X_house, y_house     = prepare_Xy(train_house, house_features)\n",
        "X_test_mansion, _    = prepare_Xy(test_mansion, mansion_features)\n",
        "X_test_house, _      = prepare_Xy(test_house, house_features)"
      ],
      "metadata": {
        "id": "7Comaq9hqQ0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. 学習関数\n",
        "# =========================\n",
        "def train_lgb(X, y):\n",
        "    model = lgb.LGBMRegressor(\n",
        "        n_estimators=2000,\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=64,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        objective=\"fair\",\n",
        "        fair_c=1\n",
        "    )\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=\"mape\", verbose=100)\n",
        "    return model"
      ],
      "metadata": {
        "id": "RLzwmUKeqUy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. モデル学習\n",
        "# =========================\n",
        "model_mansion = train_lgb(X_mansion, y_mansion)\n",
        "model_house   = train_lgb(X_house, y_house)"
      ],
      "metadata": {
        "id": "rGud5_oyqXXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =========================\n",
        "# 6. 低価格帯補正\n",
        "# =========================\n",
        "LOW_TH = 9_000_000\n",
        "LOW_SCALE = 0.83\n",
        "\n",
        "def predict_with_low_scale(model, X, low_th=LOW_TH, low_scale=LOW_SCALE):\n",
        "    y_pred = np.expm1(model.predict(X))\n",
        "    mask_low = y_pred <= low_th\n",
        "    y_pred[mask_low] *= low_scale\n",
        "    return y_pred\n",
        "\n",
        "y_pred_train_mansion = predict_with_low_scale(model_mansion, X_mansion)\n",
        "y_pred_train_house   = predict_with_low_scale(model_house, X_house)\n",
        "y_pred_test_mansion  = predict_with_low_scale(model_mansion, X_test_mansion)\n",
        "y_pred_test_house    = predict_with_low_scale(model_house, X_test_house)"
      ],
      "metadata": {
        "id": "81tyKwPSqZjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. submit 作成\n",
        "# =========================\n",
        "submit = pd.concat([\n",
        "    pd.DataFrame({\"id\": test_mansion[\"id\"], \"money_room\": y_pred_test_mansion}),\n",
        "    pd.DataFrame({\"id\": test_house[\"id\"],   \"money_room\": y_pred_test_house})\n",
        "]).sort_values(\"id\")\n",
        "\n",
        "submit.to_csv(\"submit.csv\", index=False, header=False)\n",
        "print(\"submit.csv を出力しました\")"
      ],
      "metadata": {
        "id": "TlSHkQ1hqcIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}